{"posts":[{"title":"支付宝个人收款解决方案","content":" 步骤 创建 网页/移动应用 https://open.alipay.com/develop/manage 设置 接口加签方式 添加 FROM平台 alipay.open.auth.userauth.cancelled 【用户授权取消消息】 alipay.trade.refund.depositback.completed【收单退款冲退完成通知】 产品绑定 当面付 注意事项 下载 密钥工具 https://opendocs.alipay.com/common/02kipk 开发 引入 pom &lt;dependency&gt; &lt;groupId&gt;com.alipay.sdk&lt;/groupId&gt; &lt;artifactId&gt;alipay-easysdk&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt; 样例代码 package com.mall; import com.alipay.easysdk.factory.Factory; import com.alipay.easysdk.kernel.Config; import com.alipay.easysdk.kernel.util.ResponseChecker; import com.alipay.easysdk.payment.facetoface.models.AlipayTradePrecreateResponse; import com.fasterxml.jackson.databind.ObjectMapper; import com.mall.entity.resp.AlipayTradeBaseResponse; import com.mall.util.NumberUtil; import org.apache.commons.io.IOUtils; import java.io.IOException; /** * grant * 19/11/2021 11:52 上午 * 描述： */ public class AlipayTest { public static void main(String[] args) throws Exception { // 1. 设置参数（全局只需设置一次） Factory.setOptions(getOptions()); try { // 2. 发起API调用（以创建当面付收款二维码为例） AlipayTradePrecreateResponse response = Factory.Payment.FaceToFace() .preCreate(&quot;话费充值&quot;, NumberUtil.genOrderNo(), &quot;0.1&quot;); // 3. 处理响应或异常 if (ResponseChecker.success(response)) { System.out.println(&quot;调用成功&quot;); System.out.println(response.httpBody); AlipayTradeBaseResponse alipayTradeBaseResponse = new ObjectMapper().readValue(response.httpBody, AlipayTradeBaseResponse.class); System.out.println(alipayTradeBaseResponse); } else { System.err.println(&quot;调用失败，原因：&quot; + response.msg + &quot;，&quot; + response.subMsg); } } catch (Exception e) { System.err.println(&quot;调用遭遇异常，原因：&quot; + e.getMessage()); throw new RuntimeException(e.getMessage(), e); } } private static Config getOptions() throws IOException { Config config = new Config(); config.protocol = &quot;https&quot;; config.gatewayHost = &quot;openapi.alipay.com&quot;; config.signType = &quot;RSA2&quot;; config.appId = &quot;2021002193625906&quot;; // 为避免私钥随源码泄露，推荐从文件中读取私钥字符串而不是写入源码中 config.merchantPrivateKey = IOUtils.toString( Thread.currentThread().getContextClassLoader().getResourceAsStream( &quot;config/appPrivate.txt&quot; ) );//&quot;&lt;-- 请填写您的应用私钥，例如：MIIEvQIBADANB ... ... --&gt;&quot;; //注：证书文件路径支持设置为文件系统中的路径或CLASS_PATH中的路径，优先从文件系统中加载，加载失败后会继续尝试从CLASS_PATH中加载 config.merchantCertPath = &quot;config/appCertPublicKey_2021002193625906.crt&quot;; config.alipayCertPath = &quot;config/alipayCertPublicKey_RSA2.crt&quot;; config.alipayRootCertPath = &quot;config/alipayRootCert.crt&quot;; //注：如果采用非证书模式，则无需赋值上面的三个证书路径，改为赋值如下的支付宝公钥字符串即可 // config.alipayPublicKey = &quot;&lt;-- 请填写您的支付宝公钥，例如：MIIBIjANBg... --&gt;&quot;; //可设置异步通知接收服务地址（可选） config.notifyUrl = &quot;http://110.40.196.223:28390/payNotify/alipay&quot;; //可设置AES密钥，调用AES加解密相关接口时需要（可选） // config.encryptKey = &quot;&lt;-- 请填写您的AES密钥，例如：aa4BtZ4tspm2wnXLb1ThQA== --&gt;&quot;; return config; } } ","link":"https://cooker.github.io/post/zhi-fu-bao-ge-ren-shou-kuan-jie-jue-fang-an/"},{"title":"简单动态变量文本模板","content":"import lombok.experimental.UtilityClass; import org.springframework.cglib.beans.BeanMap; import java.util.ArrayList; import java.util.HashMap; import java.util.List; import java.util.Map; import java.util.Set; import java.util.regex.Matcher; import java.util.regex.Pattern; /** * 10/11/2022 11:02 上午 * 描述： * * @author grant */ @UtilityClass public class TemplateUtils { /** * 变量占位符匹配正则 */ private static final Pattern pattern = Pattern.compile(&quot;(\\\\$\\\\{(.*?)})&quot;); /** * 解析 * * @param templateStr 模板str * @param bean 豆 * @return {@link String} */ public String parse(String templateStr, Object bean){ if (!templateStr.contains(&quot;$&quot;)){ return templateStr; } return parse(templateStr, BeanMap.create(bean)); } /** * 解析 * * @param templateStr 模板str * @param params 参数 * @return {@link String} */ public String parse(String templateStr, Map&lt;String, Object&gt; params){ if (!templateStr.contains(&quot;$&quot;)){ return templateStr; } String template = templateStr; Map&lt;String, String&gt; variableMap = getVariableMap(template); Set&lt;Map.Entry&lt;String, String&gt;&gt; entries = variableMap.entrySet(); for (Map.Entry&lt;String, String&gt; entry : entries) { String key = entry.getKey(); String value = entry.getValue(); if (params.containsKey(key)){ template = template.replace(value, String.valueOf(params.get(key))); } } return template; } /** * 解析变量名 * * @param templateStr 模板str * @return {@link List}&lt;{@link String}&gt; */ public List&lt;String&gt; parseVariableNames(String templateStr){ return new ArrayList&lt;&gt;(getVariableMap(templateStr).keySet()); } /** * 获取变量映射 * * @param templateStr 模板str * @return {@link Map}&lt;{@link String}, {@link String}&gt; */ private Map&lt;String, String&gt; getVariableMap(String templateStr) { Matcher matcher = pattern.matcher(templateStr); Map&lt;String, String&gt; variableMap = new HashMap&lt;&gt;(); while (matcher.find()) { variableMap.put(matcher.group(2).trim(), matcher.group(1)); } return variableMap; } } ","link":"https://cooker.github.io/post/jian-dan-dong-tai-bian-liang-wen-ben-mo-ban/"},{"title":"Spring-Retry 1.3.4 分析","content":" 关键变量 BackOffPolicy 执行失败处理 RetryPolicy 判断能否重试 RetryListener 执行监听 执行方法 execute 参数 retryCallback 执行方法 recoveryCallback 重试上限后执行方法 执行步骤 RetryPolicy.open 创建RetryContext RetrySynchronizationManager.register(context) 当前线程存储RetryContext doOpenInterceptors 遍历执行 RetryListener.open 判断 backOffContext 是否在context里面，FALSE：执行backOffPolicy.start 必须抛出异常才能进入重试 retryPolicy.canRetry &amp;&amp; !context.isExhaustedOnly(判断执行是否结束) 进入异常处理 registerThrowable 放入异常 doOnErrorInterceptors 遍历执行 RetryListener.onError 判断一次步骤 5 backOffPolicy.backOff 执行，进行sleep等操作 shouldRethrow 执行，state 非空则执行回滚，并抛出异常 重试超过限制，退出while handleRetryExhausted 执行，recoveryCallback.recover finally retryPolicy.close RetryListener.close RetrySynchronizationManager.clear 清理当前线程存储RetryContext ","link":"https://cooker.github.io/post/spring-retry-134-fen-xi/"},{"title":"Git 使用手册","content":"删除已合并的远程分支 git branch -r --merged origin/master | grep -vE 'master|uat|dev' | sed 's/origin///g' | xargs -I {} git push origin :{} ","link":"https://cooker.github.io/post/git-shi-yong-shou-ce/"},{"title":"GoLand 2022.2.2 破解","content":" 安装包 ja-netfilter.v3.1.zip 配置 --add-opens=java.base/jdk.internal.org.objectweb.asm=ALL-UNNAMED --add-opens=java.base/jdk.internal.org.objectweb.asm.tree=ALL-UNNAMED -javaagent:/Users/grant/work/app/ja-netfilter.v3.1/ja-netfilter.jar 激活码 PSUYBOSE34-eyJsaWNlbnNlSWQiOiJQU1VZQk9TRTM0IiwibGljZW5zZWVOYW1lIjoia2lkZHkgaW5zZWFtcyIsImFzc2lnbmVlTmFtZSI6IiIsImFzc2lnbmVlRW1haWwiOiIiLCJsaWNlbnNlUmVzdHJpY3Rpb24iOiIiLCJjaGVja0NvbmN1cnJlbnRVc2UiOmZhbHNlLCJwcm9kdWN0cyI6W3siY29kZSI6IlBTSSIsImZhbGxiYWNrRGF0ZSI6IjIwMjUtMDgtMDEiLCJwYWlkVXBUbyI6IjIwMjUtMDgtMDEiLCJleHRlbmRlZCI6dHJ1ZX0seyJjb2RlIjoiUENXTVAiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9LHsiY29kZSI6IkdPIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjpmYWxzZX0seyJjb2RlIjoiUEdPIiwiZmFsbGJhY2tEYXRlIjoiMjAyNS0wOC0wMSIsInBhaWRVcFRvIjoiMjAyNS0wOC0wMSIsImV4dGVuZGVkIjp0cnVlfSx7ImNvZGUiOiJQV1MiLCJmYWxsYmFja0RhdGUiOiIyMDI1LTA4LTAxIiwicGFpZFVwVG8iOiIyMDI1LTA4LTAxIiwiZXh0ZW5kZWQiOnRydWV9XSwibWV0YWRhdGEiOiIwMTIwMjIwODAxUFNBTjAwMDAwNSIsImhhc2giOiJUUklBTDotNTIzMzE4Njc5IiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-JWZKP0AJWKSXcl1Ep6poGhauD7GlLMbPVMompa2zVsDzjP2L82BvMo0RZTPYcGiLnP7YL7kHUNFrn2wJiNlXVwp9AnXUvVTspDqhf5MwZ/W0Aug0HpJB0BVSPM7KRL41wyN2DHGyvRJ/w4/s057IQEZWUUy2HUUM1E48WqezS7HlKQBVrrD+IFjHE2Xv4xaPt/KBFXTn+MwWBiYcKsIdDurNKjHdRwo/Gl0umRc8/CFMYK6nrgoWA13PAgHMZioQPc4DK2aVCbCDECpTGoMIsKl2jZJei+wPfOf9Ud9i0/95YEyoK8/XnkUBzsm19quFegTEVp3HhT/EMheCuvMmeQ==-MIIETDCCAjSgAwIBAgIBDTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTIwMTAxOTA5MDU1M1oXDTIyMTAyMTA5MDU1M1owHzEdMBsGA1UEAwwUcHJvZDJ5LWZyb20tMjAyMDEwMTkwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCUlaUFc1wf+CfY9wzFWEL2euKQ5nswqb57V8QZG7d7RoR6rwYUIXseTOAFq210oMEe++LCjzKDuqwDfsyhgDNTgZBPAaC4vUU2oy+XR+Fq8nBixWIsH668HeOnRK6RRhsr0rJzRB95aZ3EAPzBuQ2qPaNGm17pAX0Rd6MPRgjp75IWwI9eA6aMEdPQEVN7uyOtM5zSsjoj79Lbu1fjShOnQZuJcsV8tqnayeFkNzv2LTOlofU/Tbx502Ro073gGjoeRzNvrynAP03pL486P3KCAyiNPhDs2z8/COMrxRlZW5mfzo0xsK0dQGNH3UoG/9RVwHG4eS8LFpMTR9oetHZBAgMBAAGjgZkwgZYwCQYDVR0TBAIwADAdBgNVHQ4EFgQUJNoRIpb1hUHAk0foMSNM9MCEAv8wSAYDVR0jBEEwP4AUo562SGdCEjZBvW3gubSgUouX8bOhHKQaMBgxFjAUBgNVBAMMDUpldFByb2ZpbGUgQ0GCCQDSbLGDsoN54TATBgNVHSUEDDAKBggrBgEFBQcDATALBgNVHQ8EBAMCBaAwDQYJKoZIhvcNAQELBQADggIBABqRoNGxAQct9dQUFK8xqhiZaYPd30TlmCmSAaGJ0eBpvkVeqA2jGYhAQRqFiAlFC63JKvWvRZO1iRuWCEfUMkdqQ9VQPXziE/BlsOIgrL6RlJfuFcEZ8TK3syIfIGQZNCxYhLLUuet2HE6LJYPQ5c0jH4kDooRpcVZ4rBxNwddpctUO2te9UU5/FjhioZQsPvd92qOTsV+8Cyl2fvNhNKD1Uu9ff5AkVIQn4JU23ozdB/R5oUlebwaTE6WZNBs+TA/qPj+5/we9NH71WRB0hqUoLI2AKKyiPw++FtN4Su1vsdDlrAzDj9ILjpjJKA1ImuVcG329/WTYIKysZ1CWK3zATg9BeCUPAV1pQy8ToXOq+RSYen6winZ2OO93eyHv2Iw5kbn1dqfBw1BuTE29V2FJKicJSu8iEOpfoafwJISXmz1wnnWL3V/0NxTulfWsXugOoLfv0ZIBP1xH9kmf22jjQ2JiHhQZP7ZDsreRrOeIQ/c4yR8IQvMLfC0WKQqrHu5ZzXTH4NO3CwGWSlTY74kE91zXB5mwWAx1jig+UXYc2w4RkVhy0//lOmVya/PEepuuTTI4+UJwC7qbVlh5zfhj8oTNUXgN0AOc+Q0/WFPl1aw5VV/VrO8FCoB15lFVlpKaQ1Yh+DVU8ke+rt9Th0BCHXe0uZOEmH0nOnH/0onD ","link":"https://cooker.github.io/post/goland-202222-po-jie/"},{"title":"Linux 性能排查","content":"free 是查看内存使用情况，包括物理内存、交换内存(swap)和内核缓冲区内存。 free -h -s 3表示每隔三秒输出一次内存情况，命令如下 [1014154@cc69dd4c5-4tdb5 ~]$ free total used free shared buff/cache available Mem: 119623656 43052220 45611364 4313760 30960072 70574408 Swap: 0 0 0 [1014154@cc69dd4c5-4tdb5 ~]$ free -h -s 3 total used free shared buff/cache available Mem: 114G 41G 43G 4.1G 29G 67G Swap: 0B 0B 0B total used free shared buff/cache available Mem: 114G 41G 43G 4.1G 29G 67G Swap: 0B 0B 0B Mem：是内存的使用情况。 Swap：是交换空间的使用情况。 total：系统总的可用物理内存和交换空间大小。 used：已经被使用的物理内存和交换空间。 free：还有多少物理内存和交换空间可用使用，是真正尚未被使用的物理内存数量。 shared：被共享使用的物理内存大小。 buff/cache：被 buffer（缓冲区） 和 cache（缓存） 使用的物理内存大小。 available：还可以被应用程序使用的物理内存大小，它是从应用程序的角度看到的可用内存数量。 available： ≈ free + buffer + cache。 vmstat（推荐） vmstat（VirtualMeomoryStatistics，虚拟内存统计）是Linux中监控内存的常用工具，可对操作系统的虚拟内存、进程、CPU等的整体情况进行监视，推荐使用。 vmstat 5 3 表示每隔5秒统计一次，一共统计三次。 [1014154@cc69dd4c5-4tdb5 ~]$ vmstat 5 3 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 8 0 0 45453212 374768 30763728 0 0 14 99 1 1 11 10 78 0 1 10 0 0 45489232 374768 30763360 0 0 2 1275 95118 97908 13 11 75 0 1 6 0 0 45452908 374768 30765148 0 0 0 3996 89924 92073 12 10 78 0 1 procs r：表示运行和等待CPU时间片的进程数（就是说多少个进程真的分配到CPU），这个值如果长期大于系统CPU个数，说明CPU不足，需要增加CPU。b：表示在等待资源的进程数，比如正在等待I/O或者内存交换等。 memory swpd：表示切换到内存交换区的内存大小，即虚拟内存已使用的大小（单位KB），如果大于0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。free：表示当前空闲的物理内存。buff：表示缓冲大小，一般对块设备的读写才需要缓冲 Cache：表示缓存大小，一般作为文件系统进行缓冲，频繁访问的文件都会被缓存，如果cache值非常大说明缓存文件比较多，如果此时io中的bi比较小，说明文件系统效率比较好。 swap si：表示数据由磁盘读入内存；通俗的讲就是每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。so：表示由内存写入磁盘，也就是由内存交换区进入内存的数据大小。 注意：一般情况下si、so的值都为0，如果si、so的值长期不为0，则说明系统内存不足，需要增加系统内存 io bi：表示由块设备读入数据的总量，即读磁盘，单位kb/s bo：表示写到块设备数据的总量，即写磁盘，单位kb/s 注意：如果bi+bo的值过大，且wa值较大，则表示系统磁盘IO瓶颈。 system in：表示某一时间间隔内观测到的每秒设备终端数。cs：表示每秒产生的上下文切换次数，这个值要越小越好，太大了，要考虑调低线程或者进程的数目。例如在apache和nginx这种web服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择web服务器的进程可以由进程或者线程的峰值一直下调，压测，直到cs到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的CPU大部分浪费在上下文切换，导致CPU干正经事的时间少了，CPU没有充分利用，是不可取的。 注意：这两个值越大，则由内核消耗的CPU就越多。 CPU us：表示用户进程消耗的CPU时间百分比，us值越高，说明用户进程消耗CPU时间越多，如果长期大于50%，则需要考虑优化程序或者算法。sy：表示系统内核进程消耗的CPU时间百分比，一般来说us+sy应该小于80%，如果大于80%，说明可能存在CPU瓶颈。id：表示CPU处在空间状态的时间百分比。wa：表示IP等待所占用的CPU时间百分比，wa值越高，说明I/O等待越严重，根据经验wa的参考值为20%，如果超过20%，说明I/O等待严重，引起I/O等待的原因可能是磁盘大量随机读写造成的，也可能是磁盘或者监控器的贷款瓶颈（主要是块操作）造成的。 sar sar -u 3可以查看CUP总体消耗占比： [root@localhost ~]# sar -u 3 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年05月01日 _x86_64_ (2 CPU) 15时18分03秒 CPU %user %nice %system %iowait %steal %idle 15时18分06秒 all 0.00 0.00 0.17 0.00 0.00 99.83 15时18分09秒 all 0.00 0.00 0.17 0.00 0.00 99.83 15时18分12秒 all 0.17 0.00 0.17 0.00 0.00 99.66 15时18分15秒 all 0.00 0.00 0.00 0.00 0.00 100.00 15时18分18秒 all 0.00 0.00 0.00 0.00 0.00 100.00 %user：用户空间的CPU使用。 %nice：改变过优先级的进程的CPU使用率。 %system：内核空间的CPU使用率。 %iowait：CPU等待IO的百分比 。 %steal：虚拟机的虚拟机CPU使用的CPU。 %idle：空闲的CPU。 在以上的显示当中，主要看%iowait和%idle： 若 %iowait的值过高，表示硬盘存在I/O瓶颈； 若 %idle的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量； 若 %idle的值持续低于 10，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU； sar -n DEV 1 查看网络设备的吞吐率 $ sar -n TCP,ETCP 1 Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU) 12:17:19 AM active/s passive/s iseg/s oseg/s 12:17:20 AM 1.00 0.00 10233.00 18846.00 12:17:19 AM atmptf/s estres/s retrans/s isegerr/s orsts/s 12:17:20 AM 0.00 0.00 0.00 0.00 0.00 12:17:20 AM active/s passive/s iseg/s oseg/s 12:17:21 AM 1.00 0.00 8359.00 6039.00 12:17:20 AM atmptf/s estres/s retrans/s isegerr/s orsts/s 12:17:21 AM 0.00 0.00 0.00 0.00 0.00 sar命令在这里用于查看TCP连接状态，其中包括： active/s：每秒本地发起的TCP连接数，既通过connect调用创建的TCP连接； passive/s：每秒远程发起的TCP连接数，即通过accept调用创建的TCP连接； retrans/s：每秒TCP重传数量； TCP连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP重传可能是因为网络环境恶劣，或者服务器压力过大导致丢包。 iostat 通iostat查看磁盘总体的读写情况： [root@localhost ~]# iostat Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年05月02日 _x86_64_ (2 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.17 0.00 0.20 0.46 0.00 99.17 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 1.56 30.45 39.61 4659620 6060644 scd0 0.00 0.02 0.00 3102 0 dm-0 1.96 30.01 38.42 4591998 5878155 dm-1 0.09 0.09 0.30 13840 45328 tps：该设备每秒的传输次数。 kB_read/s：每秒从设备（drive expressed）读取的数据量； kB_wrtn/s：每秒向设备（drive expressed）写入的数据量； kB_read：读取的总数据量； kB_wrtn：写入的总数量数据量； iotop 一般先通过iostat查看是否存在io瓶颈，再使用iotop命令来定位那个进程最耗费IO： [root@localhost ~]# iotop Total DISK READ : 0.00 B/s | Total DISK WRITE : 0.00 B/s Actual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND 123931 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.02 % [kworker/1:30] 94208 be/4 xiaolyuh 0.00 B/s 0.00 B/s 0.00 % 0.00 % nautilus-desktop --force [gmain] 1 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % systemd --system --deserialize 62 2 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [kthreadd] 94211 be/4 xiaolyuh 0.00 B/s 0.00 B/s 0.00 % 0.00 % gvfsd-trash --spawner :1.4 /org/gtk/gvfs/exec_spaw/0 4 be/0 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [kworker/0:0H] 6 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [ksoftirqd/0] 7 rt/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [migration/0] 8 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [rcu_bh] 9 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [rcu_sched] 10 be/0 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % [lru-add-drain] ... 通过iotop -p pid可以查看单个进程的IO情况： [root@localhost ~]# iotop -p 124146 Total DISK READ : 0.00 B/s | Total DISK WRITE : 0.00 B/s Actual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND 124146 be/4 root 0.00 B/s 0.00 B/s 0.00 % 0.00 % java -jar arthas-demo.jar dmesg 系统日志 dmesg丨tail pidstat 1 pidstat命令输出进程的CPU占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个JAVA进程占用了将近1600%的CPU时间，既消耗了大约16个CPU核心的运算资源。 $ pidstat 1 Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU) 07:41:02 PM UID PID %usr %system %guest %CPU CPU Command 07:41:03 PM 0 9 0.00 0.94 0.00 0.94 1 rcuos/0 07:41:03 PM 0 4214 5.66 5.66 0.00 11.32 15 mesos-slave 07:41:03 PM 0 4354 0.94 0.94 0.00 1.89 8 java 07:41:03 PM 0 6521 1596.23 1.89 0.00 1598.11 27 java 07:41:03 PM 0 6564 1571.70 7.55 0.00 1579.25 28 java 07:41:03 PM 60004 60154 0.94 4.72 0.00 5.66 9 pidstat 07:41:03 PM UID PID %usr %system %guest %CPU CPU Command 07:41:04 PM 0 4214 6.00 2.00 0.00 8.00 15 mesos-slave 07:41:04 PM 0 6521 1590.00 1.00 0.00 1591.00 27 java07:41:04 PM 0 6564 1573.00 10.00 0.00 1583.00 28 java 07:41:04 PM 108 6718 1.00 0.00 0.00 1.00 0 snmp-pass 07:41:04 PM 60004 60154 1.00 4.00 0.00 5.00 9 pidstat 资料 脚本 useful-scripts 补充 查看耗时线程 使用ps -Lp #pid cu命令，查看某个进程中的线程CPU消耗排序： 使用printf '%x\\n' 98345命令做进制转换 使用jstack获取堆栈信息jstack 98344 | grep -A 10 18029 [root@localhost ~]# jstack 98344 | grep -A 10 18029 &quot;main&quot; #1 prio=5 os_prio=0 tid=0x00007fb88404b800 nid=0x18029 waiting on condition [0x00007fb88caab000] java.lang.Thread.State: TIMED_WAITING (sleeping) at java.lang.Thread.sleep(Native Method) at java.lang.Thread.sleep(Thread.java:340) at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386) at demo.MathGame.main(MathGame.java:17) &quot;VM Thread&quot; os_prio=0 tid=0x00007fb8840f2800 nid=0x1802a runnable &quot;VM Periodic Task Thread&quot; os_prio=0 tid=0x00007fb884154000 nid=0x18031 waiting on condition 「查看有多少远程的 IP 在连接本机」 #!/bin/bash # 查看有多少远程的 IP 在连接本机(不管是通过 ssh 还是 web 还是 ftp 都统计) # 使用 netstat ‐atn 可以查看本机所有连接的状态,‐a 查看所有, # -t仅显示 tcp 连接的信息,‐n 数字格式显示 # Local Address(第四列是本机的 IP 和端口信息) # Foreign Address(第五列是远程主机的 IP 和端口信息) # 使用 awk 命令仅显示第 5 列数据,再显示第 1 列 IP 地址的信息 # sort 可以按数字大小排序,最后使用 uniq 将多余重复的删除,并统计重复的次数 netstat -atn | awk '{print $5}' | awk '{print $1}' | sort -nr | uniq -c 「脚本 杀掉 tomcat 进程并重新启动」 #!/bin/bash #kill tomcat pid pidlist=`ps -ef|grep apache-tomcat-7.0.75|grep -v &quot;grep&quot;|awk '{print $2}'` #找到tomcat的PID号 echo &quot;tomcat Id list :$pidlist&quot; //显示pid kill -9 $pidlist #杀掉改进程 echo &quot;KILL $pidlist:&quot; //提示进程以及被杀掉 echo &quot;service stop success&quot; echo &quot;start tomcat&quot; cd /opt/apache-tomcat-7.0.75 pwd rm -rf work/* cd bin ./startup.sh #;tail -f ../logs/catalina.out 「统计当前 Linux 系统中可以登录计算机的账户有多少个」 #!/bin/bash # 统计当前 Linux 系统中可以登录计算机的账户有多少个 #方法 1: grep &quot;bash$&quot; /etc/passwd | wc -l #方法 2： awk -f : '/bash$/{x++}end{print x}' /etc/passwd 「备份 MySQL 表数据」 #!/bin/sh source /etc/profile dbName=mysql tableName=db echo [`date +'%Y-%m-%d %H:%M:%S'`]' start loading data...' mysql -uroot -proot -P3306 ${dbName} -e &quot;LOAD DATA LOCAL INFILE '# /home/wenmin/wenxing.txt' INTO TABLE ${tableName} FIELDS TERMINATED BY ';'&quot; echo [`date +'%Y-%m-%d %H:%M:%S'`]' end loading data...' exit EOF 「脚本 每周 5 使用 tar 命令备份/var/log 下的所有日志文件」 #!/bin/bash # 每周 5 使用 tar 命令备份/var/log 下的所有日志文件 # vim /root/logbak.sh # 编写备份脚本,备份后的文件名包含日期标签,防止后面的备份将前面的备份数据覆盖 # 注意 date 命令需要使用反引号括起来,反引号在键盘&lt;tab&gt;键上面 tar -czf log-`date +%Y%m%d`.tar.gz /var/log # crontab -e #编写计划任务，执行备份脚本 00 03 * * 5 /home/wenmin/datas/logbak.sh 「定义要监控的页面地址，对 tomcat 状态进行重启或维护」 #!/bin/sh # function:自动监控tomcat进程，挂了就执行重启操作 # author:huanghong # DEFINE # 获取tomcat PPID TomcatID=$(ps -ef |grep tomcat |grep -w 'apache-tomcat-7.0.75'|grep -v 'grep'|awk '{print $2}') # tomcat_startup StartTomcat=/opt/apache-tomcat-7.0.75/bin/startup.sh #TomcatCache=/usr/apache-tomcat-5.5.23/work # 定义要监控的页面地址 WebUrl=http://192.168.254.118:8080/ # 日志输出 GetPageInfo=/dev/null TomcatMonitorLog=/tmp/TomcatMonitor.log Monitor() { echo &quot;[info]开始监控tomcat...[$(date +'%F %H:%M:%S')]&quot; if [ $TomcatID ] then echo &quot;[info]tomcat进程ID为:$TomcatID.&quot; # 获取返回状态码 TomcatServiceCode=$(curl -s -o $GetPageInfo -m 10 --connect-timeout 10 $WebUrl -w %{http_code}) if [ $TomcatServiceCode -eq 200 ];then echo &quot;[info]返回码为$TomcatServiceCode,tomcat启动成功,页面正常.&quot; else echo &quot;[error]访问出错，状态码为$TomcatServiceCode,错误日志已输出到$GetPageInfo&quot; echo &quot;[error]开始重启tomcat&quot; kill -9 $TomcatID # 杀掉原tomcat进程 sleep 3 #rm -rf $TomcatCache # 清理tomcat缓存 $StartTomcat fi else echo &quot;[error]进程不存在!tomcat自动重启...&quot; echo &quot;[info]$StartTomcat,请稍候......&quot; #rm -rf $TomcatCache $StartTomcat fi echo &quot;------------------------------&quot; } Monitor&gt;&gt;$TomcatMonitorLog ","link":"https://cooker.github.io/post/linux-xing-neng-pai-cha/"},{"title":"consul 部署","content":"config 配置 https://www.consul.io/docs/agent/config/config-files 单机 node_name = &quot;s1&quot; server = true bootstrap = true ui_config { enabled = true } datacenter = &quot;dc1&quot; data_dir = &quot;/Volumes/SAO/data/consul/data&quot; log_level = &quot;INFO&quot; # 有多ip时需要指定 bind_addr = &quot;127.0.0.1&quot; connect { enabled = true } 启动命令 consul agent -config-file=/Volumes/SAO/data/consul/conf/config.hcl -server 集群 补充 跨域 http_config { response_headers { Access-Control-Allow-Origin = &quot;*&quot; } } 停机 consul leave 安全 https://learn.hashicorp.com/tutorials/consul/access-control-setup-production#bootstrap-the-acl-system ","link":"https://cooker.github.io/post/consul-bu-shu/"},{"title":"Canal Mysql增量数据同步","content":"安装 https://github.com/alibaba/canal/releases canal.admin-1.1.6.tar.gz canal.deployer-1.1.6.tar.gz 启动Admin 登录 http://127.0.0.1:8089/ 配置 Instance配置 启动deployer sh bin/startup.sh local 测试代码 package com.alibaba.otter.canal.example; import com.alibaba.otter.canal.client.CanalConnector; import com.alibaba.otter.canal.client.CanalConnectors; import com.alibaba.otter.canal.common.utils.AddressUtils; import com.alibaba.otter.canal.protocol.CanalEntry.*; import com.alibaba.otter.canal.protocol.Message; import java.net.InetSocketAddress; import java.util.List; /** * 21/7/2022 6:01 下午 * 描述： * * @author grant */ public class SimpleCanalClientExample { public static void main(String args[]) { // 创建链接 CanalConnector connector = CanalConnectors.newSingleConnector(new InetSocketAddress(AddressUtils.getHostIp(), 11111), &quot;example&quot;, &quot;&quot;, &quot;&quot;); int batchSize = 1000; int emptyCount = 0; try { connector.connect(); connector.subscribe(&quot;.*\\\\..*&quot;); connector.rollback(); int totalEmptyCount = 120; while (emptyCount &lt; totalEmptyCount) { Message message = connector.getWithoutAck(batchSize); // 获取指定数量的数据 long batchId = message.getId(); int size = message.getEntries().size(); if (batchId == -1 || size == 0) { emptyCount++; System.out.println(&quot;empty count : &quot; + emptyCount); try { Thread.sleep(1000); } catch (InterruptedException e) { } } else { emptyCount = 0; // System.out.printf(&quot;message[batchId=%s,size=%s] \\n&quot;, batchId, size); printEntry(message.getEntries()); } connector.ack(batchId); // 提交确认 // connector.rollback(batchId); // 处理失败, 回滚数据 } System.out.println(&quot;empty too many times, exit&quot;); } finally { connector.disconnect(); } } private static void printEntry(List&lt;Entry&gt; entrys) { for (Entry entry : entrys) { if (entry.getEntryType() == EntryType.TRANSACTIONBEGIN || entry.getEntryType() == EntryType.TRANSACTIONEND) { continue; } RowChange rowChage = null; try { rowChage = RowChange.parseFrom(entry.getStoreValue()); } catch (Exception e) { throw new RuntimeException(&quot;ERROR ## parser of eromanga-event has an error , data:&quot; + entry.toString(), e); } EventType eventType = rowChage.getEventType(); System.out.println(String.format(&quot;================&amp;gt; binlog[%s:%s] , name[%s,%s] , eventType : %s&quot;, entry.getHeader().getLogfileName(), entry.getHeader().getLogfileOffset(), entry.getHeader().getSchemaName(), entry.getHeader().getTableName(), eventType)); for (RowData rowData : rowChage.getRowDatasList()) { if (eventType == EventType.DELETE) { printColumn(rowData.getBeforeColumnsList()); } else if (eventType == EventType.INSERT) { printColumn(rowData.getAfterColumnsList()); } else { System.out.println(&quot;-------&amp;gt; before&quot;); printColumn(rowData.getBeforeColumnsList()); System.out.println(&quot;-------&amp;gt; after&quot;); printColumn(rowData.getAfterColumnsList()); } } } } private static void printColumn(List&lt;Column&gt; columns) { for (Column column : columns) { System.out.println(column.getName() + &quot; : &quot; + column.getValue() + &quot; update=&quot; + column.getUpdated()); } } } 错误汇总 解决办法 example/instance.propertios 添加 canal.instance.filter.black.regex=.*\\\\.BASE.* 解决办法 登陆 http://127.0.0.1:8089/ 配置 Instance配置 ","link":"https://cooker.github.io/post/canal-mysql-zeng-liang-shu-ju-tong-bu/"},{"title":"MongoDB 5.0.9 分片配置","content":"https://www.mongodb.com/docs/v3.4/tutorial/deploy-sharded-cluster-ranged-sharding/ 组件 mongos 负责router config 负责配置（必须副本集） mongod 负责存储（必须副本集） Config 配置 processManagement: fork: true net: bindIp: localhost port: [**自定义端口**] storage: dbPath: /Volumes/SAO/data/mongo-sharding/db/c systemLog: destination: file path: &quot;/Volumes/SAO/data/mongo-sharding/logs/mongoc.log&quot; logAppend: true storage: journal: enabled: true replication: oplogSizeMB: 1024 replSetName: rs2 sharding: clusterRole: configsvr mongod 配置 processManagement: fork: true net: bindIp: localhost port: [**自定义端口**] storage: dbPath: /Volumes/SAO/data/mongo-sharding/db/s1 systemLog: destination: file path: &quot;/Volumes/SAO/data/mongo-sharding/logs/mongod1.log&quot; logAppend: true storage: journal: enabled: true sharding: clusterRole: shardsvr replication: replSetName: sh1 operationProfiling: mode: slowOp slowOpThresholdMs: 500 mongos 配置 processManagement: fork: true net: bindIp: localhost port: 27018 systemLog: destination: file path: &quot;/Volumes/SAO/data/mongo-sharding/logs/mongos.log&quot; logAppend: true sharding: configDB: rs2/127.0.0.1:27021,127.0.0.1:27022,127.0.0.1:27023 #步骤 初始化mongod副本集 添加sharding ","link":"https://cooker.github.io/post/mongodb-509-fen-pian-pei-zhi/"},{"title":"MongoDB 5.0.9 注意事项","content":"rs.reconfig() 会导致连接主节点客户端下线 mongo.uri 配置 https://www.mongodb.com/docs/manual/reference/connection-string/ ","link":"https://cooker.github.io/post/mongodb-509-zhu-yi-shi-xiang/"},{"title":"MongoDB 5.0.9 常用命令","content":"mongosh shell 自定义编辑器 方式1 export EDITOR=vim 启动 mongo 或 mongosh 方式2 config.set( &quot;editor&quot;, &quot;vi&quot; ) 使用编辑器编辑函数 edit myFunction 基础命令 config config https://www.mongodb.com/docs/mongodb-shell/reference/configure-shell-settings-api/ 开启异常打印 config.set(&quot;showStackTraces&quot;, true) CRUD Insert db.collection.insertOne() db.collection.insertMany() db.collection.updateOne() when used with the upsert: true option. db.collection.updateMany() when used with the upsert: true option. db.collection.findAndModify() when used with the upsert: true option. db.collection.findOneAndUpdate() when used with the upsert: true option. db.collection.findOneAndReplace() when used with the upsert: true option. db.collection.bulkWrite() Query db.collection.find() 维护 独立的方式启动mongod，进行维护 mongod --setParameter skipShardingConfigurationChecks=true 主节点降级 rs.stepDown() 重新同步副本集 不能用mongodump ","link":"https://cooker.github.io/post/mongodb-509-chang-yong-ming-ling/"},{"title":"MongoDB 5.0.9 优化","content":"设置日志级别 db.adminCommand( { setParameter: 1, logLevel: 2 } ) 慢操作配置 https://www.mongodb.com/docs/v5.0/reference/configuration-options/#mongodb-setting-operationProfiling.slowOpSampleRate operationProfiling: mode: all filter: '{ op: &quot;query&quot;, millis: { $gt: 2000 } }' 或 operationProfiling: mode: all slowOpThresholdMs: 2000 slowOpSampleRate: 1 慢日志查询 //查询耗时2s db.getCollection(&quot;system.profile&quot;).find({millis: {$gt: 2000}}) //设置监控级别 db.setProfilingLevel(1, { slowms: 2000 }) //查询TOP 10慢操作 db.system.profile.find().limit(10).sort( { ts : -1 } ).pretty() 写操作验证 db.products.insert( { item: &quot;envelopes&quot;, qty : 100, type: &quot;Clasp&quot; }, { writeConcern: { w: &quot;majority&quot; , wtimeout: 5000 } } ) 修改默认写 cfg = rs.conf() cfg.settings.getLastErrorDefaults = { w: &quot;majority&quot;, wtimeout: 5000 } rs.reconfig(cfg) 节点切换 //降级 rs.stepDown(30) 安全 账号管理 // 管理用户 db.createUser({ user: &quot;admin&quot;, pwd: &quot;admin&quot;, roles: [{ role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; }] }) // 管理数据库 db.createUser({user: &quot;root&quot;,pwd: &quot;root&quot;, roles: [ { role: &quot;root&quot;, db: &quot;admin&quot; } ]}) // 普通库管理员 db.createUser({user: &quot;test&quot;,pwd: &quot;test&quot;, roles: [ { role: &quot;dbAdmin&quot;, db: &quot;test&quot; } ]}) 开启认证 security: authorization: enabled keyFile: /Users/grant/Downloads/keyFile/key.key 生成key openssl rand -base64 756 &gt; &lt;path-to-keyfile&gt; chmod 400 &lt;path-to-keyfile&gt; 登陆账号 db.getSiblingDB(&quot;admin&quot;).auth(&quot;root&quot;, passwordPrompt()) mongo --port 27017 -u myUserAdmin --authenticationDatabase 'admin' -p 压缩文件 use local db.runCommand({ &quot;compact&quot; : &quot;oplog.rs&quot; } ) 注意：维护时段，不能有写入操作 ","link":"https://cooker.github.io/post/mongodb-509-you-hua/"},{"title":"MongoDB 5.0.9 安装","content":"单机 配置 processManagement: fork: true net: bindIp: localhost port: 27017 storage: dbPath: /Volumes/SAO/data/mongo/27017/db systemLog: destination: file path: &quot;/Volumes/SAO/data/mongo/27017/mongod.log&quot; logAppend: true storage: journal: enabled: true 启动命令 mongod -f /Volumes/SAO/data/mongo/27017/mongod.conf --fork 副本集 配置 replication: oplogSizeMB: 64 replSetName: rs2 添加集群 rs.initiate( { _id: &quot;rs2&quot;, version: 1, members: [ { _id: 0, host : &quot;127.0.0.1:27017&quot; }, { _id: 1, host : &quot;127.0.0.1:27018&quot; }, { _id: 2, host : &quot;127.0.0.1:27019&quot; } ] } ) 启动指令 mongod -f /Volumes/SAO/data/mongo/27017/mongod.conf --fork mongod -f /Volumes/SAO/data/mongo/27018/mongod.conf --fork mongod -f /Volumes/SAO/data/mongo/27019/mongod.conf --fork 常用指令 https://www.mongodb.com/docs/v5.0/reference/replication/ 隐藏副本集成员 cfg = rs.conf() cfg.members 里面 hidden 设置为 true priority 设置为 0 节点操作 //添加 rs.add( { host: &quot;mongodb3.example.net:27017&quot;, priority: 1, votes: 1} ) //删除 rs.remove( { host: &quot;mongodb3.example.net:27017&quot;} ) 添加仲裁器 //只投票，不保存数据 rs.addArb(&quot;m1.example.net:27017&quot;) 允许查询 rs.secondaryOk() 优雅关闭 ps -ef | grep mongo | grep -v grep | awk '{print &quot;kill -15 &quot;$2}' 状态查看 //检查关于操作日志的副本集成员的当前状态 rs.printReplicationInfo() rs.status() ","link":"https://cooker.github.io/post/mongodb-509-an-zhuang/"},{"title":"MAC 个人工具箱","content":"网络工具 switchhosts host管理工具 Charles，网络抓包 Paw，http 接口请求 Postman，http 接口请求 ClashX，网络代理 vpn Proxyman，网络抓包 系统扩展 Alfred 4，快捷启动工具 Bartender 4，菜单管理工具 AltTab，窗口切换 Keka，压缩工具 XtraFinder，finder增强 KeyboardHolder，输入法管理 Magnet，窗口操作 MenubarX，菜单栏嵌入浏览器 Mounty，NFTS 硬盘加载 NewFileMenu，菜单增强 OpenInTerminal，菜单终端 Paste，粘贴板增强 Shottr，截图 CheatSheet，长按显示快捷键 开发增强 戴铭的开发小册子，一本活的开发手册。使用 SwiftUI + Combine + Swift Concurrency Aysnc/Await Actor + GitHub API 开发的 macOS 应用 Dash，开发文档 Gridea，写博客 JD-GUI，java 反编译 Medis，redis客户端 RDM，redis客户端 服务器管理 Termius，远程终端 Transmit，FTP 客户端 远程办公 Parsec Idea 配置 2021.2.2 idea默认配置 ","link":"https://cooker.github.io/post/mac-ge-ren-gong-ju-xiang/"},{"title":"网址导航","content":"资料网站整理分享 Linux 描述 地址 shell 脚本教学 https://archlinuxstudio.github.io/ShellTutorial/#/ ansible 自动化运维 https://docs.ansible.com/ansible/latest/ sed 命令 https://wangchujiang.com/linux-command/c/sed.html 外挂编程 描述 地址 微软DOC https://docs.microsoft.com/en-us/ windows 消息机制 https://www.youtube.com/watch?v=OUvsBZD1_RY&amp;list=PLe3E2noDbHE7H6CsmCsWzG4nWENfJqJfl 计算机网络 https://www.youtube.com/watch?v=laDvEPzOYQ4&amp;list=PLjAs5kw1NNs2hsblGz3WjBHs1EO8KcuZs&amp;index=15 赛博朋克外挂 https://k4yt3x.com/用-cheat-engine-给赛博朋克-2077-写%E��简单注入外挂/ 易语言 https://www.inhsoft.com/forum.php DLL 查看器 https://github.com/icsharpcode/ILSpy/releases 逆向分析扫雷 https://bbs.pediy.com/thread-262471.htm 工具合集 https://live.sysinternals.com 资料 描述 地址 面试 https://www.aliyundrive.com/s/jKQP6zbTBLv 设计模式 https://refactoringguru.cn/design-patterns/java MybatisPlus https://mp.weixin.qq.com/s/SyHfv2qO6I-TCHlyPLtNxA Spring 文档 https://docs.spring.io/spring-framework/docs/current/reference/html/index.html fink 教程 https://www.aliyundrive.com/s/aYpzmEV673j 面试准备 描述 地址 高并发 https://github.com/qiurunze123/threadandjuc JVM https://blog.csdn.net/wj1314250/article/details/117755865 垃圾回收器 https://mp.weixin.qq.com/s/o8U5VpVky3dmKuHAVLASUA Java 知识进阶 https://github.com/doocs/advanced-java 面试汇总 https://mp.weixin.qq.com/s?__biz=MzIyNDU2ODA4OQ%3D%3D&amp;idx=1&amp;mid=2247486846&amp;scene=21&amp;sn=75bd4dcdbaad73191a1e4dbf691c118a 源码剖析 https://github.com/doocs/source-code-hunter 代码分析和重构 https://modernizing.phodal.com/ 技术论文 https://www.aminer.cn/topic/60113b0e92c7f9be21388f15 RabbitMQ 描述 地址 vivo 高可用架构实践 https://mp.weixin.qq.com/s/7s9-RsLWgiVvw28U51J0bA Redis 描述 地址 基础知识 https://www.cnblogs.com/tobyhomels/p/12505681.html 从高频问题透视核心原理 https://mp.weixin.qq.com/s/UEKO7f3jngWOk8q0A63VKg 25张图解Redis连环面试！击溃面试官！ https://mp.weixin.qq.com/s3ln9VAB_heYTI7yvxnp2bw Elasticsearch 描述 地址 论坛 https://learnku.com/elasticsearch MySQL 描述 地址 MVCC https://www.52pojie.cn/thread-1512271-1-1.html 视频教程 描述 地址 大国之治 https://www.aliyundrive.com/s/YZstFhopmuW 日语入门到精通 https://www.aliyundrive.com/s/mfhNiCWSSxk ","link":"https://cooker.github.io/post/wang-zhi-dao-hang/"},{"title":"服务性能调优","content":"系统监控工具 nmon bpytop https://github.com/aristocratos/bpytop JVM 开启远程JMS -Dcom.sun.management.jmxremote. port=14000 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false Java 性能分析指标 CPU 内存分析 线程分析 JMC 获取性能数据 jcmd &lt;pid&gt; JFR.start jcmd &lt;pid&gt; JFR.dump filename=recording jfr jcmd &lt;pid&gt; JFR.stop Arthas 获取单接口调用链耗时 wrk 获取web接口性能数据 JMH 精准测量方法性能 ","link":"https://cooker.github.io/post/linux-jian-kong-gong-ju-bpytop/"},{"title":"TiDB 入门","content":"安装 curl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh 部署，指定实例 方式一 tiup playground 方式二 tiup playground v5.0.0 --db 2 --pd 3 --kv 3 --monitor 卸载 tiup clean --all ","link":"https://cooker.github.io/post/tidb-ru-men/"},{"title":"Spring refresh() 过程","content":"public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { // 准备此上下文以进行刷新。 prepareRefresh(); // 告诉子类刷新内部bean工厂。 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 准备 bean 工厂以在此上下文中使用。 prepareBeanFactory(beanFactory); try { // 允许在上下文子类中对 bean 工厂进行后处理。 postProcessBeanFactory(beanFactory); // 调用在上下文中注册为 bean 的工厂处理器。 invokeBeanFactoryPostProcessors(beanFactory); // 注册拦截bean创建的bean处理器。 registerBeanPostProcessors(beanFactory); // 为此上下文初始化消息源。 initMessageSource(); // 为这个上下文初始化事件多播器。 initApplicationEventMulticaster(); // 在特定的上下文子类中初始化其他特殊bean。 onRefresh(); // 检查并注册侦听器bean。 registerListeners(); // 实例化所有剩余的(非lazy-init)单例。 finishBeanFactoryInitialization(beanFactory); // 最后一步:发布相应的事件。 finishRefresh(); } } ","link":"https://cooker.github.io/post/spring-refresh-guo-cheng/"},{"title":"七大排序算法","content":" 测试用例 public static void main(String[] args) { int[] arr = {3,5,4,3,2,6,7,2,1}; String str = Arrays.stream( sort(Arrays.copyOf(arr, arr.length)) ).mapToObj(i-&gt;i+&quot;&quot;).collect(Collectors.joining()); Arrays.sort(arr); System.out.println( Arrays.stream(arr).mapToObj(i-&gt;i+&quot;&quot;).collect(Collectors.joining()).equals(str) ); } 选择排序 public static int[] sort(int []rows) { if (rows == null || rows.length == 0) return rows; int len = rows.length; for (int i = 0; i &lt; len - 1; i++) { int min = i; for (int j = i+1; j &lt; len; j++) { if (rows[min] &gt; rows[j]) { min = j; } } int tmp = rows[i]; rows[i] = rows[min]; rows[min] = tmp; } return rows; } 快速排序 public static int[] sort(int[] rows, int lo, int hi) { if (lo &gt;= hi) { return rows; } int index = part(rows, lo, hi); sort(rows, lo, index-1); sort(rows, index+1, hi); return rows; } private static int part(int[] rows, int lo, int hi) { //固定分隔 int key = rows[lo]; while (lo &lt; hi){ while (rows[hi] &gt;= key &amp;&amp; hi &gt; lo) { hi--; } rows[lo] = rows[hi]; while (rows[lo] &lt;= key &amp;&amp; hi &gt; lo) { lo++; } rows[hi] = rows[lo]; } rows[hi] = key; return hi; } 冒泡排序 public static int[] sort(int []rows) { for (int i = 0; i &lt; rows.length - 1; i++) { for (int j = 0; j &lt; rows.length - i - 1; j++) { if (rows[j] &gt; rows[j+1]) { rows[j] = rows[j] ^ rows[j+1]; rows[j + 1] = rows[j] ^ rows[j+1]; rows[j] = rows[j] ^ rows[j+1]; } } } return rows; } 插入排序 public static int[] sort(int []rows) { for (int i = 1; i &lt; rows.length; i++) { for (int j = i; j &gt; 0 ; j--) { if (rows[j] &lt; rows[j-1]) { rows[j] = rows[j] ^ rows[j-1]; rows[j - 1] = rows[j] ^ rows[j-1]; rows[j] = rows[j] ^ rows[j-1]; } } } return rows; } ","link":"https://cooker.github.io/post/qi-da-pai-xu-suan-fa/"},{"title":"服务排查 Linux常用操作","content":" lsof 查找日志路径 lsof -i [pid] | grp log 查询不规则日志 获取行号 grep -n &quot;[条件]&quot; ./hello.txt 查询内容 sed -n '[开始行号],[结束行号]p' ./hello.txt ","link":"https://cooker.github.io/post/fu-wu-pai-cha-linux-chang-yong-cao-zuo/"},{"title":"RabbitMQ 延迟队列配置","content":" 选择 Exchanges 新建 type：topic 选择 Queues 新建 添加 Message TTL 消息存活时间，单位ms 添加 Dead letter exchange 消息过期后，将转发的队列 x-dead-letter-routing-key 可不填，填默认 '#' 路由字段 绑定 Exchanges 和 Queues ","link":"https://cooker.github.io/post/rabbitmq-yan-chi-dui-lie-pei-zhi/"},{"title":"MySQL 避免全表扫描","content":"https://dev.mysql.com/doc/refman/5.6/en/table-scan-avoidance.html 表很小，直接全票扫描比走索引快 ON 或 WHERE 条件里面没有用索引 条件里面的索引列使用常量进行比较 一张表一个索引条件的占比很大，可以添加一个基数小的索引条件进行查询 用FORCE INDEX (index_for_column)强制走索引、【use index (index_for_column) 只是建议走索引】 SELECT * FROM t1, t2 FORCE INDEX (index_for_column) WHERE t1.col_name=t2.col_name; --max-seeks-for-key=1000或使用SET max_seeks_for_key=1000告诉优化器假定没有键扫描导致超过1000个键查找。请参见第5.1.7节“服务器系统变量”。 ","link":"https://cooker.github.io/post/mysql-bi-mian-quan-biao-sao-miao/"},{"title":"MySQL 联合索引不生效","content":" 包含 != 或 &lt;&gt; 有or，其中一个or没有建立索引 like 查询以 % 开头 列类型为字符串，查询条件未加 '' 使用 =null 此列索引不生效，必须使用 is null 查询优化器使用全部扫描要比使用索引快 5.6 之前索引下推，索引a使用like %导致 ","link":"https://cooker.github.io/post/mysql-lian-he-suo-yin-bu-sheng-xiao/"},{"title":"Spring AOP 日志拦截","content":" 注解 @Inherited @Documented @Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME) public @interface ShowEvent { String value() default &quot;&quot;; //环境，默认全部环境打日志 String[] profile() default &quot;&quot;; } 实现 import cn.hutool.core.lang.UUID; import com.fasterxml.jackson.annotation.JsonIgnore; import com.google.common.collect.Maps; import lombok.AllArgsConstructor; import lombok.Builder; import lombok.Data; import lombok.NoArgsConstructor; import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang3.ArrayUtils; import org.apache.commons.lang3.StringUtils; import org.apache.commons.lang3.tuple.Pair; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.aspectj.lang.reflect.MethodSignature; import org.springframework.beans.factory.annotation.Value; import org.springframework.core.annotation.Order; import org.springframework.stereotype.Component; import org.springframework.util.CollectionUtils; import org.springframework.validation.BindingResult; import org.springframework.web.context.request.RequestAttributes; import org.springframework.web.context.request.RequestContextHolder; import org.springframework.web.context.request.ServletRequestAttributes; import org.springframework.web.multipart.MultipartFile; import javax.annotation.Resource; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; import javax.validation.ConstraintViolation; import javax.validation.Validator; import javax.validation.executable.ExecutableValidator; import java.io.Serializable; import java.lang.reflect.Method; import java.util.*; import java.util.stream.Collectors; @Order(1) @Slf4j @Component @Aspect public class LogsAspect { private static String ING_HEADERS[] = new String[]{ &quot;accept&quot;, &quot;accept-encoding&quot;, &quot;accept-language&quot;, &quot;connection&quot;, &quot;content-length&quot;, &quot;cookie&quot;, &quot;host&quot;, &quot;token&quot; }; @Value(&quot;${spring.profiles.active}&quot;) private String env; @Resource private Validator validator; @Pointcut(&quot;@annotation(com.x2era.xcloud.order.base.ShowEvent) &quot;) public void cutReq() { } @Around(&quot;cutReq()&quot;) public Object globalLog(ProceedingJoinPoint joinPoint) throws Throwable { Class&lt;?&gt; clazz = joinPoint.getTarget().getClass(); MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); Method realMethod = clazz.getMethod(signature.getName(), method.getParameterTypes()); ShowEvent showEvent = method.getAnnotation(ShowEvent.class); boolean canLog = Arrays.stream(showEvent.profile()).anyMatch(pf-&gt;&quot;&quot;.equals(pf) || StringUtils.equalsAnyIgnoreCase(pf, env)); // Class&lt;?&gt; returnType = realMethod.getReturnType(); Object[] args = joinPoint.getArgs(); String uuid = UUID.fastUUID().toString(true); //校验参数 if (canLog) { Pair&lt;Boolean, String&gt; validateArgs = argsValidate(joinPoint.getTarget(), realMethod, args); if (!validateArgs.getLeft()) { log.error(&quot; {} 全局日志 {}&quot;, uuid, JsonUtil.toJson(LogData.builder() .title(String.format(&quot;%s validateError, %s.%s&quot;, showEvent.value(), clazz.getSimpleName(), realMethod.getName())) .request(getArgs(args)) .response(validateArgs.getRight()) .build())); // log.error(&quot;{} {}参数校验不通过&quot;, showEvent.value(), method.getName()); } } Object result = null; long start = DateUtils.timestamp(); try { result = joinPoint.proceed(); } catch (IllegalArgumentException e) { log.error(&quot;{} 全局日志 参数错误：{}&quot;, uuid, e.getMessage(), e); return Result.error(ResultCodeEnum.ILLEGAL_PARAM_ERROR.getKey(), ResultCodeEnum.ILLEGAL_PARAM_ERROR.getValue()); } catch (Exception e) { log.error(&quot;{} Exception occurred at .&quot;, uuid, e); throw e; } finally { if (canLog) { log.info(&quot;{} 全局日志 {}&quot;, uuid, JsonUtil.toJson(LogData.builder() .title(String.format(&quot;%s %s.%s&quot;,showEvent.value() ,clazz.getSimpleName(), realMethod.getName())) .header(getHeaders()) .request(getArgs(args)) .response(result) .costs(DateUtils.timestamp() - start).build())); } } return result; } private Map&lt;String, String&gt; getHeaders() { Map&lt;String, String&gt; result = new HashMap&lt;&gt;(); RequestAttributes requestAttr = RequestContextHolder.currentRequestAttributes(); if (requestAttr instanceof ServletRequestAttributes) { HttpServletRequest request = ((ServletRequestAttributes) requestAttr).getRequest(); if (request != null) { Enumeration&lt;String&gt; hk = request.getHeaderNames(); while (hk.hasMoreElements()) { String key = hk.nextElement(); if (!ArrayUtils.contains(ING_HEADERS, key.toLowerCase())) { result.put(key, request.getHeader(key)); } } } } return result; } private Object[] getArgs(Object[] args) { Object[] arguments = new Object[args.length]; for (int i = 0; i &lt; args.length; i++) { if (args[i] instanceof ServletRequest || args[i] instanceof ServletResponse || args[i] instanceof MultipartFile || args[i] instanceof BindingResult ) { //ServletRequest不能序列化，从入参里排除，否则报异常：java.lang.IllegalStateException: It is illegal to call this method if the current request is not in asynchronous mode (i.e. isAsyncStarted() returns false) //ServletResponse不能序列化 从入参里排除，否则报异常：java.lang.IllegalStateException: getOutputStream() has already been called for this response continue; } arguments[i] = args[i]; } return arguments; } private Pair&lt;Boolean, String&gt; argsValidate(Object validateParamService, Method method, Object[] args) { Pair&lt;Boolean, String&gt; validate1 = methodArgsValidate(validateParamService, method, args); if (!validate1.getLeft()) { return validate1; } Pair&lt;Boolean, String&gt; validate2 = methodArgsFieldValidate(args); if (!validate2.getLeft()) { return validate2; } return Pair.of(true, null); } @Data @Builder @NoArgsConstructor @AllArgsConstructor public static class LogData implements Serializable { private String title; private Map&lt;String, String&gt; header; private Object request; private Object response; private Long costs; } /** * 方法参数校验 * * @param validateParamService 拦截的service * @param method 具体拦截的方法 * @param args 方法参数 * @return true|false、errorMessage */ private Pair&lt;Boolean, String&gt; methodArgsValidate(Object validateParamService, Method method, Object[] args) { if (ArrayUtils.isEmpty(args)) { return Pair.of(true, null); } ExecutableValidator executableValidator = validator.forExecutables(); Set&lt;ConstraintViolation&lt;Object&gt;&gt; constraintViolationSet = executableValidator.validateParameters(validateParamService, method, args); if (CollectionUtils.isEmpty(constraintViolationSet)) { return Pair.of(true, null); } List&lt;String&gt; errorMessage = constraintViolationSet.stream() .map(e -&gt; e.getPropertyPath().toString() + e.getMessage()) .collect(Collectors.toList()); return Pair.of(false, JsonUtil.toJson(errorMessage)); } /** * 方法参数的属性校验 * * @param args args * @return true | false */ private Pair&lt;Boolean, String&gt; methodArgsFieldValidate(Object[] args) { if (ArrayUtils.isEmpty(args)) { return Pair.of(true, null); } for (Object arg : args) { if (arg != null) { Set&lt;ConstraintViolation&lt;Object&gt;&gt; error = validator.validate(arg); if (!CollectionUtils.isEmpty(error)) { List&lt;String&gt; errorMessage = error.stream() .map(e -&gt; e.getPropertyPath().toString() + e.getMessage()) .collect(Collectors.toList()); return Pair.of(false, JsonUtil.toJson(errorMessage)); } } } return Pair.of(true, null); } } ","link":"https://cooker.github.io/post/spring-aop-ri-zhi-lan-jie/"},{"title":"Spring AOP","content":"AOP execution: 用于匹配方法执行的连接点。这是使用Spring AOP时要使用的主要切入点指示符。 within: 将匹配限制为某些类型内的连接点（使用Spring AOP时，在匹配类型内声明的方法的执行）。 this: 限制匹配到连接点（使用Spring AOP时方法的执行），其中bean引用（Spring AOP代理）是给定类型的实例。 target: 限制匹配到连接点（使用Spring AOP时方法的执行）的匹配，其中目标对象（正在代理的应用程序对象）是给定类型的实例。 args: 限制匹配到连接点（使用Spring AOP时方法的执行）的匹配，其中参数是给定类型的实例 @target: 限制匹配到连接点（使用Spring AOP时方法的执行）的匹配，其中执行对象的类具有给定类型的注释。 @args: 限制匹配的连接点（使用Spring AOP时方法的执行），其中传递的实际参数的运行时类型具有给定类型的注释。 @within: 限制匹配到具有给定注释的类型内的连接点（使用Spring AOP时，使用给定注释的类型中声明的方法的执行）。 @annotation: 将匹配点限制为连接点的主题（在Spring AOP中执行的方法）具有给定注释的连接点。 .Java @Pointcut(&quot;execution(* transfer(..))&quot;) // the pointcut expression private void anyOldTransfer() {} // the pointcut signature .Java @Pointcut(&quot;execution(public * \\*(..))&quot;) private void anyPublicOperation() {} // &lt;1&gt; @Pointcut(&quot;within(com.xyz.someapp.trading..*)&quot;) private void inTrading() {} // &lt;2&gt; @Pointcut(&quot;anyPublicOperation() &amp;&amp; inTrading()&quot;) private void tradingOperation() {} // &lt;3&gt; .Java package com.xyz.someapp; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; @Aspect public class SystemArchitecture { /** * 如果以com.xyz.someapp.web包或该包下的任何子包中的类型定义该方法，则该连接点位于Web层中。 */ @Pointcut(&quot;within(com.xyz.someapp.web..*)&quot;) public void inWebLayer() {} /** * A join point is in the service layer if the method is defined * in a type in the com.xyz.someapp.service package or any sub-package * under that. */ @Pointcut(&quot;within(com.xyz.someapp.service..*)&quot;) public void inServiceLayer() {} /** * A join point is in the data access layer if the method is defined * in a type in the com.xyz.someapp.dao package or any sub-package * under that. */ @Pointcut(&quot;within(com.xyz.someapp.dao..*)&quot;) public void inDataAccessLayer() {} /** * A business service is the execution of any method defined on a service * interface. This definition assumes that interfaces are placed in the * &quot;service&quot; package, and that implementation types are in sub-packages. * * If you group service interfaces by functional area (for example, * in packages com.xyz.someapp.abc.service and com.xyz.someapp.def.service) then * the pointcut expression &quot;execution(* com.xyz.someapp..service.*.*(..))&quot; * could be used instead. * * Alternatively, you can write the expression using the 'bean' * PCD, like so &quot;bean(*Service)&quot;. (This assumes that you have * named your Spring service beans in a consistent fashion.) */ @Pointcut(&quot;execution(* com.xyz.someapp..service.*.*(..))&quot;) public void businessService() {} /** * A data access operation is the execution of any method defined on a * dao interface. This definition assumes that interfaces are placed in the * &quot;dao&quot; package, and that implementation types are in sub-packages. */ @Pointcut(&quot;execution(* com.xyz.someapp.dao.*.*(..))&quot;) public void dataAccessOperation() {} } .Java import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; @Aspect public class BeforeExample { @Before(&quot;com.xyz.myapp.SystemArchitecture.dataAccessOperation()&quot;) public void doAccessCheck() { // ... } } .Java import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.AfterReturning; @Aspect public class AfterReturningExample { @AfterReturning( pointcut=&quot;com.xyz.myapp.SystemArchitecture.dataAccessOperation()&quot;, returning=&quot;retVal&quot;) public void doAccessCheck(Object retVal) { // ... } } .Java import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.AfterThrowing; @Aspect public class AfterThrowingExample { @AfterThrowing( pointcut=&quot;com.xyz.myapp.SystemArchitecture.dataAccessOperation()&quot;, throwing=&quot;ex&quot;) public void doRecoveryActions(DataAccessException ex) { // ... } } .Java @Before(&quot;com.xyz.myapp.SystemArchitecture.dataAccessOperation() &amp;&amp; args(account,..)&quot;) public void validateAccount(Account account) { // ... } .Java @Pointcut(&quot;com.xyz.myapp.SystemArchitecture.dataAccessOperation() &amp;&amp; args(account,..)&quot;) private void accountDataAccessOperation(Account account) {} @Before(&quot;accountDataAccessOperation(account)&quot;) public void validateAccount(Account account) { // ... } .Java @Before(&quot;com.xyz.lib.Pointcuts.anyPublicMethod() &amp;&amp; @annotation(auditable)&quot;) public void audit(Auditable auditable) { AuditCode code = auditable.value(); // ... } Spring AOP可以处理类声明和方法参数中使用的泛型。假设您具有如下通用类型： .Java @Before(&quot;execution(* ..Sample+.sampleGenericMethod(*)) &amp;&amp; args(param)&quot;) public void beforeSampleMethod(MyType param) { // Advice implementation } .Java @Aspect public class UsageTracking { @DeclareParents(value=&quot;com.xzy.myapp.service.*+&quot;, defaultImpl=DefaultUsageTracked.class) public static UsageTracked mixin; @Before(&quot;com.xyz.myapp.SystemArchitecture.businessService() &amp;&amp; this(usageTracked)&quot;) public void recordUsage(UsageTracked usageTracked) { usageTracked.incrementUseCount(); } } .Java @Aspect(&quot;perthis(com.xyz.myapp.SystemArchitecture.businessService())&quot;) public class MyAspect { private int someState; @Before(com.xyz.myapp.SystemArchitecture.businessService()) public void recordServiceUsage() { // ... } } ","link":"https://cooker.github.io/post/spring-aop-cao-gao/"},{"title":"Feign header透传","content":"@Configuration public class FeignAcceptHeaderConfig implements RequestInterceptor { static ThreadLocal&lt;Map&lt;String, String&gt;&gt; headerLocal = new ThreadLocal&lt;Map&lt;String, String&gt;&gt;(); @Override public void apply(RequestTemplate template) { Map&lt;String, String&gt; map = headerLocal.get(); if (map != null) { Set&lt;String&gt; strings = map.keySet(); for (String key : strings) { template.header(key, map.get(key)); } } } public static void setHeaderLocal(Map&lt;String, String&gt; headers) { headerLocal.set(headers); } public static void rmHeaderLocal() { headerLocal.remove(); } } ","link":"https://cooker.github.io/post/feign-header-tou-chuan/"},{"title":"分布式事务","content":"事务的四大特性ACID 原子性 原子性要求，事务是一个不可分割的执行单元，事务中的所有操作要么全都执行，要么全都不执行。 一致性 一致性要求，事务在开始前和结束后，数据库的完整性约束没有被破坏。 隔离性 事务的执行是相互独立的，它们不会相互干扰，一个事务不会看到另一个正在运行过程中的事务的数据。 持久性 持久性要求，一个事务完成之后，事务的执行结果必须是持久化保存的。即使数据库发生崩溃，在数据库恢复后事务提交的结果仍然不会丢失。 CAP理论说的是：在一个分布式系统中，最多只能满足C、A、P中的两个需求。 CAP的含义： C：Consistency一致性 同一数据的多个副本是否实时相同。 A：Availability 可用性 可用性：一定时间内＆系统返回一个明确的结果 则称为该系统可用。 P：Partition tolerance 分区容错性 将同一服务分布在多个系统中，从而保证某一个系统宕机，仍然有其他系统提供相同的服务。 提升整体性能 当业务量猛增，单个服务器已经无法满足我们的业务需求的时候，就需要使用分布式系 统，使用多个节点提供相同的功能，从而整体上提升系统的性能，这就是使用分布式系 统的第一个原因。 实现分区容错性 单一节点或 多个节点处于相同的网络环境下，那么会存在一定的风险，万一该机房断 电、该地区发生自然灾害，那么业务系统就全面瘫痪了。为了防止这一问题，采用分布 式系统，将多个子系统分布在不同的地域、不同的机房中，从而保证系统高可用性。 ","link":"https://cooker.github.io/post/fen-bu-shi-shi-wu/"},{"title":"Bash 速查表","content":"############################################################################## BASH CHEATSHEET (中文速查表) - by skywind (created on 2018/02/14) Version: 47, Last Modified: 2019/09/24 17:58 https://github.com/skywind3000/awesome-cheatsheets ############################################################################## ############################################################################## 常用快捷键（默认使用 Emacs 键位） ############################################################################## CTRL+A # 移动到行首，同 CTRL+B # 向后移动，同 CTRL+C # 结束当前命令 CTRL+D # 删除光标前的字符，同 ，或者没有内容时，退出会话 CTRL+E # 移动到行末，同 CTRL+F # 向前移动，同 CTRL+G # 退出当前编辑（比如正在 CTRL+R 搜索历史时） CTRL+H # 删除光标左边的字符，同 CTRL+K # 删除光标位置到行末的内容 CTRL+L # 清屏并重新显示 CTRL+N # 移动到命令历史的下一行，同 CTRL+O # 类似回车，但是会显示下一行历史 CTRL+P # 移动到命令历史的上一行，同 CTRL+R # 历史命令反向搜索，使用 CTRL+G 退出搜索 CTRL+S # 历史命令正向搜索，使用 CTRL+G 退出搜索 CTRL+T # 交换前后两个字符 CTRL+U # 删除字符到行首 CTRL+V # 输入字符字面量，先按 CTRL+V 再按任意键 CTRL+W # 删除光标左边的一个单词 CTRL+X # 列出可能的补全 CTRL+Y # 粘贴前面 CTRL+u/k/w 删除过的内容 CTRL+Z # 暂停前台进程返回 bash，需要时可用 fg 将其切换回前台 CTRL+_ # 撤销（undo），有的终端将 CTRL+_ 映射为 CTRL+/ 或 CTRL+7 ALT+b # 向后（左边）移动一个单词 ALT+d # 删除光标后（右边）一个单词 ALT+f # 向前（右边）移动一个单词 ALT+t # 交换字符 ALT+BACKSPACE # 删除光标前面一个单词，类似 CTRL+W，但不影响剪贴板 CTRL+X CTRL+X # 连续按两次 CTRL+X，光标在当前位置和行首来回跳转 CTRL+X CTRL+E # 用你指定的编辑器，编辑当前命令 ############################################################################## BASH 基本操作 ############################################################################## exit # 退出当前登陆 env # 显示环境变量 echo $SHELL # 显示你在使用什么 SHELL bash # 使用 bash，用 exit 返回 which bash # 搜索 $PATH，查找哪个程序对应命令 bash whereis bash # 搜索可执行，头文件和帮助信息的位置，使用系统内建数据库 whatis bash # 查看某个命令的解释，一句话告诉你这是干什么的 clear # 清初屏幕内容 reset # 重置终端（当你不小心 cat 了一个二进制，终端状态乱掉时使用） ############################################################################## 目录操作 ############################################################################## cd # 返回自己 $HOME 目录 cd {dirname} # 进入目录 pwd # 显示当前所在目录 mkdir {dirname} # 创建目录 mkdir -p {dirname} # 递归创建目录 pushd {dirname} # 目录压栈并进入新目录 popd # 弹出并进入栈顶的目录 dirs -v # 列出当前目录栈 cd - # 回到之前的目录 cd -{N} # 切换到目录栈中的第 N个目录，比如 cd -2 将切换到第二个 ############################################################################## 文件操作 ############################################################################## ls # 显示当前目录内容，后面可接目录名：ls {dir} 显示指定目录 ls -l # 列表方式显示目录内容，包括文件日期，大小，权限等信息 ls -1 # 列表方式显示目录内容，只显示文件名称，减号后面是数字 1 ls -a # 显示所有文件和目录，包括隐藏文件（.开头的文件/目录名） ln -s {fn} {link} # 给指定文件创建一个软链接 cp {src} {dest} # 拷贝文件，cp -r dir1 dir2 可以递归拷贝（目录） rm {fn} # 删除文件，rm -r 递归删除目录，rm -f 强制删除 mv {src} {dest} # 移动文件，如果 dest 是目录，则移动，是文件名则覆盖 touch {fn} # 创建或者更新一下制定文件 cat {fn} # 输出文件原始内容 any_cmd &gt; {fn} # 执行任意命令并将标准输出重定向到指定文件 more {fn} # 逐屏显示某文件内容，空格翻页，q 退出 less {fn} # 更高级点的 more，更多操作，q 退出 head {fn} # 显示文件头部数行，可用 head -3 abc.txt 显示头三行 tail {fn} # 显示文件尾部数行，可用 tail -3 abc.txt 显示尾部三行 tail -f {fn} # 持续显示文件尾部数据，可用于监控日志 nano {fn} # 使用 nano 编辑器编辑文件 vim {fn} # 使用 vim 编辑文件 diff {f1} {f2} # 比较两个文件的内容 wc {fn} # 统计文件有多少行，多少个单词 chmod 644 {fn} # 修改文件权限为 644，可以接 -R 对目录循环改权限 chgrp group {fn} # 修改文件所属的用户组 chown user1 {fn} # 修改文件所有人为 user1, chown user1:group1 fn 可以修改组 file {fn} # 检测文件的类型和编码 basename {fn} # 查看文件的名字（不包括路径） dirname {fn} # 查看文件的路径（不包括名字） grep {pat} {fn} # 在文件中查找出现过 pat 的内容 grep -r {pat} . # 在当前目录下递归查找所有出现过 pat 的文件内容 stat {fn} # 显示文件的详细信息 ############################################################################## 用户管理 ############################################################################## whoami # 显示我的用户名 who # 显示已登陆用户信息，w / who / users 内容略有不同 w # 显示已登陆用户信息，w / who / users 内容略有不同 users # 显示已登陆用户信息，w / who / users 内容略有不同 passwd # 修改密码，passwd {user} 可以用于 root 修改别人密码 finger {user} # 显示某用户信息，包括 id, 名字, 登陆状态等 adduser {user} # 添加用户 deluser {user} # 删除用户 w # 查看谁在线 su # 切换到 root 用户 su - # 切换到 root 用户并登陆（执行登陆脚本） su {user} # 切换到某用户 su -{user} # 切换到某用户并登陆（执行登陆脚本） id {user} # 查看用户的 uid，gid 以及所属其他用户组 id -u {user} # 打印用户 uid id -g {user} # 打印用户 gid write {user} # 向某用户发送一句消息 last # 显示最近用户登陆列表 last {user} # 显示登陆记录 lastb # 显示失败登陆记录 lastlog # 显示所有用户的最近登陆记录 sudo {command} # 以 root 权限执行某命令 ############################################################################## 进程管理 ############################################################################## ps # 查看当前会话进程 ps ax # 查看所有进程，类似 ps -e ps aux # 查看所有进程详细信息，类似 ps -ef ps auxww # 查看所有进程，并且显示进程的完整启动命令 ps -u {user} # 查看某用户进程 ps axjf # 列出进程树 ps xjf -u {user} # 列出某用户的进程树 ps -eo pid,user,command # 按用户指定的格式查看进程 ps aux | grep httpd # 查看名为 httpd 的所有进程 ps --ppid {pid} # 查看父进程为 pid 的所有进程 pstree # 树形列出所有进程，pstree 默认一般不带，需安装 pstree {user} # 进程树列出某用户的进程 pstree -u # 树形列出所有进程以及所属用户 pgrep {procname} # 搜索名字匹配的进程的 pid，比如 pgrep apache2 kill {pid} # 结束进程 kill -9 {pid} # 强制结束进程，9/SIGKILL 是强制不可捕获结束信号 kill -KILL {pid} # 强制执行进程，kill -9 的另外一种写法 kill -l # 查看所有信号 kill -l TERM # 查看 TERM 信号的编号 killall {procname} # 按名称结束所有进程 pkill {procname} # 按名称结束进程，除名称外还可以有其他参数 top # 查看最活跃的进程 top -u {user} # 查看某用户最活跃的进程 any_command &amp; # 在后台运行某命令，也可用 CTRL+Z 将当前进程挂到后台 jobs # 查看所有后台进程（jobs） bg # 查看后台进程，并切换过去 fg # 切换后台进程到前台 fg {job} # 切换特定后台进程到前台 trap cmd sig1 sig2 # 在脚本中设置信号处理命令 trap &quot;&quot; sig1 sig2 # 在脚本中屏蔽某信号 trap - sig1 sig2 # 恢复默认信号处理行为 nohup {command} # 长期运行某程序，在你退出登陆都保持它运行 nohup {command} &amp; # 在后台长期运行某程序 disown {PID|JID} # 将进程从后台任务列表（jobs）移除 wait # 等待所有后台进程任务结束 ############################################################################## 常用命令：SSH / 系统信息 / 网络 ############################################################################## ssh user@host # 以用户 user 登陆到远程主机 host ssh -p {port} user@host # 指定端口登陆主机 ssh-copy-id user@host # 拷贝你的 ssh key 到远程主机，避免重复输入密码 scp {fn} user@host:path # 拷贝文件到远程主机 scp user@host:path dest # 从远程主机拷贝文件回来 scp -P {port} ... # 指定端口远程拷贝文件 uname -a # 查看内核版本等信息 man {help} # 查看帮助 man -k {keyword} # 查看哪些帮助文档里包含了该关键字 info {help} # 查看 info pages，比 man 更强的帮助系统 uptime # 查看系统启动时间 date # 显示日期 cal # 显示日历 vmstat # 显示内存和 CPU 使用情况 vmstat 10 # 每 10 秒打印一行内存和 CPU情况，CTRL+C 退出 free # 显示内存和交换区使用情况 df # 显示磁盘使用情况 du # 显示当前目录占用，du . --max-depth=2 可以指定深度 uname # 显示系统版本号 hostname # 显示主机名称 showkey -a # 查看终端发送的按键编码 ping {host} # ping 远程主机并显示结果，CTRL+C 退出 ping -c N {host} # ping 远程主机 N 次 traceroute {host} # 侦测路由连通情况 mtr {host} # 高级版本 traceroute host {domain} # DNS 查询，{domain} 前面可加 -a 查看详细信息 whois {domain} # 取得域名 whois 信息 dig {domain} # 取得域名 dns 信息 route -n # 查看路由表 netstat -a # 列出所有端口 netstat -an # 查看所有连接信息，不解析域名 netstat -anp # 查看所有连接信息，包含进程信息（需要 sudo） netstat -l # 查看所有监听的端口 netstat -t # 查看所有 TCP 链接 netstat -lntu # 显示所有正在监听的 TCP 和 UDP 信息 netstat -lntup # 显示所有正在监听的 socket 及进程信息 netstat -i # 显示网卡信息 netstat -rn # 显示当前系统路由表，同 route -n ss -an # 比 netstat -an 更快速更详细 ss -s # 统计 TCP 的 established, wait 等 wget {url} # 下载文件，可加 --no-check-certificate 忽略 ssl 验证 wget -qO- {url} # 下载文件并输出到标准输出（不保存） curl -sL {url} # 同 wget -qO- {url} 没有 wget 的时候使用 sz {file} # 发送文件到终端，zmodem 协议 rz # 接收终端发送过来的文件 ############################################################################## 变量操作 ############################################################################## varname=value # 定义变量 varname=value command # 定义子进程变量并执行子进程 echo $varname # 查看变量内容 echo $$ # 查看当前 shell 的进程号 echo $! # 查看最近调用的后台任务进程号 echo $? # 查看最近一条命令的返回码 export VARNAME=value # 设置环境变量（将会影响到子进程） array[0]=valA # 定义数组 array[1]=valB array[2]=valC array=([0]=valA [1]=valB [2]=valC) # 另一种方式 array=(valA valB valC) # 另一种方式 {array[i]} # 取得数组中的元素 {#array[@]} # 取得数组的长度 ${#array[i]} # 取得数组中某个变量的长度 declare -a # 查看所有数组 declare -f # 查看所有函数 declare -F # 查看所有函数，仅显示函数名 declare -i # 查看所有整数 declare -r # 查看所有只读变量 declare -x # 查看所有被导出成环境变量的东西 declare -p varname # 输出变量是怎么定义的（类型+值） {varname:-word} # 如果变量不为空则返回变量，否则返回 word {varname:=word} # 如果变量不为空则返回变量，否则赋值成 word 并返回 {varname:?message} # 如果变量不为空则返回变量，否则打印错误信息并退出 {varname:+word} # 如果变量不为空则返回 word，否则返回 null ${varname:offset:len} # 取得字符串的子字符串 {variable#pattern} # 如果变量头部匹配 pattern，则删除最小匹配部分返回剩下的 {variable##pattern} # 如果变量头部匹配 pattern，则删除最大匹配部分返回剩下的 {variable%pattern} # 如果变量尾部匹配 pattern，则删除最小匹配部分返回剩下的 {variable%%pattern} # 如果变量尾部匹配 pattern，则删除最大匹配部分返回剩下的 {variable/pattern/str} # 将变量中第一个匹配 pattern 的替换成 str，并返回 {variable//pattern/str} # 将变量中所有匹配 pattern 的地方替换成 str 并返回 ${#varname} # 返回字符串长度 *(patternlist) # 零次或者多次匹配 +(patternlist) # 一次或者多次匹配 ?(patternlist) # 零次或者一次匹配 @(patternlist) # 单词匹配 !(patternlist) # 不匹配 array=(text) # 按空格分隔 text 成数组，并赋值给变量 IFS=&quot;/&quot; array=(text) # 按斜杆分隔字符串 text 成数组，并赋值给变量 text=&quot;{array[*]}&quot; # 用空格链接数组并赋值给变量 text=(IFS=/; echo &quot;${array[*]}&quot;) # 用斜杠链接数组并赋值给变量 A=( foo bar &quot;a b c&quot; 42 ) # 数组定义 B=(&quot;{A[@]:1:2}&quot;) # 数组切片：B=( bar &quot;a b c&quot; ) C=(&quot;{A[@]:1}&quot;) # 数组切片：C=( bar &quot;a b c&quot; 42 ) echo &quot;{B[@]}&quot; # bar a b c echo &quot;{B[1]}&quot; # a b c echo &quot;{C[@]}&quot; # bar a b c 42 echo &quot;{C[@]: -2:2}&quot; # a b c 42 减号前的空格是必须的 (UNIX command) # 运行命令，并将标准输出内容捕获并返回 varname=(id -u user) # 将用户名为 user 的 uid 赋值给 varname 变量 num=(expr 1 + 2) # 兼容 posix sh 的计算，使用 expr 命令计算结果 num=(expr $num + 1) # 数字自增 expr 2 * ( 2 + 3 ) # 兼容 posix sh 的复杂计算，输出 10 num=$((1 + 2)) # 计算 1+2 赋值给 num，使用 bash 独有的 ((..))计算num=((..)) 计算 num=((..))计算num=((num + 1)) # 变量递增 num=((num + 1)) # 变量递增，双括号内的 $ 可以省略 num=$((1 + (2 + 3) * 2)) # 复杂计算 ############################################################################## 事件指示符 ############################################################################## !! # 上一条命令 !^ # 上一条命令的第一个单词 !:n # 上一条命令的第n个单词 !:n-$ # 上一条命令的第n个单词到最后一个单词 !$ # 上一条命令的最后一个单词 !-n:$ # 上n条命令的最后一个单词 !string # 最近一条包含string的命令 !string1string2 # 最近一条包含string1的命令, 快速替换string1为string2 !# # 本条命令之前所有的输入内容 !#:n # 本条命令之前的第n个单词, 快速备份cp /etc/passwd !#:1.bak ############################################################################## 函数 ############################################################################## 定义一个新函数 function myfunc() { # 1代表第一个参数，1 代表第一个参数，1代表第一个参数，N 代表第 N 个参数 # $# 代表参数个数 # $0 代表被调用者自身的名字 # @代表所有参数，类型是个数组，想传递所有参数给其他命令用cmd&quot;@ 代表所有参数，类型是个数组，想传递所有参数给其他命令用 cmd &quot;@代表所有参数，类型是个数组，想传递所有参数给其他命令用cmd&quot;@&quot; # $* 空格链接起来的所有参数，类型是字符串 {shell commands ...} } myfunc # 调用函数 myfunc myfunc arg1 arg2 arg3 # 带参数的函数调用 myfunc &quot;@&quot; # 将所有参数传递给函数 myfunc &quot;{array[@]}&quot; # 将一个数组当作多个参数传递给函数 shift # 参数左移 unset -f myfunc # 删除函数 declare -f # 列出函数定义 ############################################################################## 条件判断（兼容 posix sh 的条件判断）：man test ############################################################################## statement1 &amp;&amp; statement2 # and 操作符 statement1 || statement2 # or 操作符 exp1 -a exp2 # exp1 和 exp2 同时为真时返回真（POSIX XSI扩展） exp1 -o exp2 # exp1 和 exp2 有一个为真就返回真（POSIX XSI扩展） ( expression ) # 如果 expression 为真时返回真，输入注意括号前反斜杆 ! expression # 如果 expression 为假那返回真 str1 = str2 # 判断字符串相等，如 [ &quot;x&quot;=&quot;x&quot; = &quot;x&quot;=&quot;y&quot; ] &amp;&amp; echo yes str1 != str2 # 判断字符串不等，如 [ &quot;x&quot;!=&quot;x&quot; != &quot;x&quot;!=&quot;y&quot; ] &amp;&amp; echo yes str1 &lt; str2 # 字符串小于，如 [ &quot;x&quot; \\&lt; &quot;y&quot; ] &amp;&amp; echo yes str2 &gt; str2 # 字符串大于，注意 &lt; 或 &gt; 是字面量，输入时要加反斜杆 -n str1 # 判断字符串不为空（长度大于零） -z str1 # 判断字符串为空（长度等于零） -a file # 判断文件存在，如 [ -a /tmp/abc ] &amp;&amp; echo &quot;exists&quot; -d file # 判断文件存在，且该文件是一个目录 -e file # 判断文件存在，和 -a 等价 -f file # 判断文件存在，且该文件是一个普通文件（非目录等） -r file # 判断文件存在，且可读 -s file # 判断文件存在，且尺寸大于0 -w file # 判断文件存在，且可写 -x file # 判断文件存在，且执行 -N file # 文件上次修改过后还没有读取过 -O file # 文件存在且属于当前用户 -G file # 文件存在且匹配你的用户组 file1 -nt file2 # 文件1 比 文件2 新 file1 -ot file2 # 文件1 比 文件2 旧 num1 -eq num2 # 数字判断：num1 == num2 num1 -ne num2 # 数字判断：num1 != num2 num1 -lt num2 # 数字判断：num1 &lt; num2 num1 -le num2 # 数字判断：num1 &lt;= num2 num1 -gt num2 # 数字判断：num1 &gt; num2 num1 -ge num2 # 数字判断：num1 &gt;= num2 ############################################################################## 分支控制：if 和经典 test，兼容 posix sh 的条件判断语句 ############################################################################## test {expression} # 判断条件为真的话 test 程序返回0 否则非零 [ expression ] # 判断条件为真的话返回0 否则非零 test &quot;abc&quot; = &quot;def&quot; # 查看返回值 echo $? 显示 1，因为条件为假 test &quot;abc&quot; != &quot;def&quot; # 查看返回值 echo $? 显示 0，因为条件为真 test -a /tmp; echo $? # 调用 test 判断 /tmp 是否存在，并打印 test 的返回值 [ -a /tmp ]; echo $? # 和上面完全等价，/tmp 肯定是存在的，所以输出是 0 test cond &amp;&amp; cmd1 # 判断条件为真时执行 cmd1 [ cond ] &amp;&amp; cmd1 # 和上面完全等价 [ cond ] &amp;&amp; cmd1 || cmd2 # 条件为真执行 cmd1 否则执行 cmd2 判断 /etc/passwd 文件是否存在 经典的 if 语句就是判断后面的命令返回值为0的话，认为条件为真，否则为假 if test -e /etc/passwd; then echo &quot;alright it exists ... &quot; else echo &quot;it doesn't exist ... &quot; fi 和上面完全等价，[ 是个和 test 一样的可执行程序，但最后一个参数必须为 ] 这个名字为 &quot;[&quot; 的可执行程序一般就在 /bin 或 /usr/bin 下面，比 test 优雅些 if [ -e /etc/passwd ]; then echo &quot;alright it exists ... &quot; else echo &quot;it doesn't exist ... &quot; fi 和上面两个完全等价，其实到 bash 时代 [ 已经是内部命令了，用 enable 可以看到 [ -e /etc/passwd ] &amp;&amp; echo &quot;alright it exists&quot; || echo &quot;it doesn't exist&quot; 判断变量的值 if [ &quot;varname&quot;=&quot;foo&quot;];thenecho&quot;thisisfoo&quot;elif[&quot;varname&quot; = &quot;foo&quot; ]; then echo &quot;this is foo&quot; elif [ &quot;varname&quot;=&quot;foo&quot;];thenecho&quot;thisisfoo&quot;elif[&quot;varname&quot; = &quot;bar&quot; ]; then echo &quot;this is bar&quot; else echo &quot;neither&quot; fi 复杂条件判断，注意 || 和 &amp;&amp; 是完全兼容 POSIX 的推荐写法 if [ $x -gt 10 ] &amp;&amp; [ $x -lt 20 ]; then echo &quot;yes, between 10 and 20&quot; fi 可以用 &amp;&amp; 命令连接符来做和上面完全等价的事情 [ $x -gt 10 ] &amp;&amp; [ $x -lt 20 ] &amp;&amp; echo &quot;yes, between 10 and 20&quot; 小括号和 -a -o 是 POSIX XSI 扩展写法，小括号是字面量，输入时前面要加反斜杆 if [ ( $x -gt 10 ) -a ( $x -lt 20 ) ]; then echo &quot;yes, between 10 and 20&quot; fi 同样可以用 &amp;&amp; 命令连接符来做和上面完全等价的事情 [ ( $x -gt 10 ) -a ( $x -lt 20 ) ] &amp;&amp; echo &quot;yes, between 10 and 20&quot; 判断程序存在的话就执行 [ -x /bin/ls ] &amp;&amp; /bin/ls -l 如果不考虑兼容 posix sh 和 dash 这些的话，可用 bash 独有的 ((..)) 和 [[..]]: https://www.ibm.com/developerworks/library/l-bash-test/index.html ############################################################################## 流程控制：while / for / case / until ############################################################################## while 循环 while condition; do statements done i=1 while [ $i -le 10 ]; do echo i;i=i; i=i;i=(expr $i + 1) done for 循环：上面的 while 语句等价 for i in {1..10}; do echo $i done for name [in list]; do statements done for 列举某目录下面的所有文件 for f in /home/*; do echo $f done bash 独有的 (( .. )) 语句，更接近 C 语言，但是不兼容 posix sh for (( initialisation ; ending condition ; update )); do statements done 和上面的写法等价 for ((i = 0; i &lt; 10; i++)); do echo $i; done case 判断 case expression in pattern1 ) statements ;; pattern2 ) statements ;; * ) otherwise ;; esac until 语句 until condition; do statements done select 语句 select name [in list]; do statements that can use $name done ############################################################################## 命令处理 ############################################################################## command ls # 忽略 alias 直接执行程序或者内建命令 ls builtin cd # 忽略 alias 直接运行内建的 cd 命令 enable # 列出所有 bash 内置命令，或禁止某命令 help {builtin_command} # 查看内置命令的帮助（仅限 bash 内置命令） eval $script # 对 script 变量中的字符串求值（执行） ############################################################################## 输出/输入 重定向 ############################################################################## cmd1 | cmd2 # 管道，cmd1 的标准输出接到 cmd2 的标准输入 &lt; file # 将文件内容重定向为命令的标准输入 file # 将命令的标准输出重定向到文件，会覆盖文件 file # 将命令的标准输出重定向到文件，追加不覆盖 | file # 强制输出到文件，即便设置过：set -o noclobber n&gt;| file # 强制将文件描述符 n的输出重定向到文件 &lt;&gt; file # 同时使用该文件作为标准输入和标准输出 n&lt;&gt; file # 同时使用文件作为文件描述符 n 的输出和输入 n&gt; file # 重定向文件描述符 n 的输出到文件 n&lt; file # 重定向文件描述符 n 的输入为文件内容 n&gt;&amp; # 将标准输出 dup/合并 到文件描述符 n n&lt;&amp; # 将标准输入 dump/合并 定向为描述符 n n&gt;&amp;m # 文件描述符 n 被作为描述符 m 的副本，输出用 n&lt;&amp;m # 文件描述符 n 被作为描述符 m 的副本，输入用 &amp;&gt;file # 将标准输出和标准错误重定向到文件 &lt;&amp;- # 关闭标准输入 &amp;- # 关闭标准输出 n&gt;&amp;- # 关闭作为输出的文件描述符 n n&lt;&amp;- # 关闭作为输入的文件描述符 n diff &lt;(cmd1) &lt;(cmd2) # 比较两个命令的输出 ############################################################################## 文本处理 - cut ############################################################################## cut -c 1-16 # 截取每行头16个字符 cut -c 1-16 file # 截取指定文件中每行头 16个字符 cut -c3- # 截取每行从第三个字符开始到行末的内容 cut -d':' -f5 # 截取用冒号分隔的第五列内容 cut -d';' -f2,10 # 截取用分号分隔的第二和第十列内容 cut -d' ' -f3-7 # 截取空格分隔的三到七列 echo &quot;hello&quot; | cut -c1-3 # 显示 hel echo &quot;hello sir&quot; | cut -d' ' -f2 # 显示 sir ps | tr -s &quot; &quot; | cut -d &quot; &quot; -f 2,3,4 # cut 搭配 tr 压缩字符 ############################################################################## 文本处理 - awk / sed ############################################################################## awk '{print $5}' file # 打印文件中以空格分隔的第五列 awk -F ',' '{print $5}' file # 打印文件中以逗号分隔的第五列 awk '/str/ {print $2}' file # 打印文件中包含 str 的所有行的第二列 awk -F ',' '{print $NF}' file # 打印逗号分隔的文件中的每行最后一列 awk '{s+=$1} END {print s}' file # 计算所有第一列的合 awk 'NR%3==1' file # 从第一行开始，每隔三行打印一行 sed 's/find/replace/' file # 替换文件中首次出现的字符串并输出结果 sed '10s/find/replace/' file # 替换文件第 10 行内容 sed '10,20s/find/replace/' file # 替换文件中 10-20 行内容 sed -r 's/regex/replace/g' file # 替换文件中所有出现的字符串 sed -i 's/find/replace/g' file # 替换文件中所有出现的字符并且覆盖文件 sed -i '/find/i\\newline' file # 在文件的匹配文本前插入行 sed -i '/find/a\\newline' file # 在文件的匹配文本后插入行 sed '/line/s/find/replace/' file # 先搜索行特征再执行替换 sed -e 's/f/r/' -e 's/f/r' file # 执行多次替换 sed 's#find#replace#' file # 使用 # 替换 / 来避免 pattern 中有斜杆 sed -i -r 's/^\\s+//g' file # 删除文件每行头部空格 sed '/^/d&#039; file # 删除文件空行并打印 sed -i &#039;s/\\s\\+//' file # 删除文件每行末尾多余空格 sed -n '2p' file # 打印文件第二行 sed -n '2,5p' file # 打印文件第二到第五行 ############################################################################## 排序 - sort ############################################################################## sort file # 排序文件 sort -r file # 反向排序（降序） sort -n file # 使用数字而不是字符串进行比较 sort -t: -k 3n /etc/passwd # 按 passwd 文件的第三列进行排序 sort -u file # 去重排序 ############################################################################## 快速跳转 - https://github.com/rupa/z ############################################################################## source /path/to/z.sh # .bashrc 中初始化 z.sh z # 列出所有历史路径以及他们的权重 z foo # 跳到历史路径中匹配 foo 的权重最大的目录 z foo bar # 跳到历史路径中匹配 foo 和 bar 权重最大的目录 z -l foo # 列出所有历史路径中匹配 foo 的目录及权重 z -r foo # 按照最高访问次数优先进行匹配跳转 z -t foo # 按照最近访问优先进行匹配跳转 ############################################################################## 键盘绑定 ############################################################################## bind '&quot;\\eh&quot;:&quot;\\C-b&quot;' # 绑定 ALT+h 为光标左移，同 CTRL+b / bind '&quot;\\el&quot;:&quot;\\C-f&quot;' # 绑定 ALT+l 为光标右移，同 CTRL+f / bind '&quot;\\ej&quot;:&quot;\\C-n&quot;' # 绑定 ALT+j 为下条历史，同 CTRL+n / bind '&quot;\\ek&quot;:&quot;\\C-p&quot;' # 绑定 ALT+k 为上条历史，同 CTRL+p / bind '&quot;\\eH&quot;:&quot;\\eb&quot;' # 绑定 ALT+H 为光标左移一个单词，同 ALT-b bind '&quot;\\eL&quot;:&quot;\\ef&quot;' # 绑定 ALT+L 为光标右移一个单词，同 ALT-f bind '&quot;\\eJ&quot;:&quot;\\C-a&quot;' # 绑定 ALT+J 为移动到行首，同 CTRL+a / bind '&quot;\\eK&quot;:&quot;\\C-e&quot;' # 绑定 ALT+K 为移动到行末，同 CTRL+e / bind '&quot;\\e;&quot;:&quot;ls -l\\n&quot;' # 绑定 ALT+; 为执行 ls -l 命令 ############################################################################## 网络管理：ip / ifconfig / nmap ... ############################################################################## ip a # 显示所有网络地址，同 ip address ip a show eth1 # 显示网卡 IP 地址 ip a add 172.16.1.23/24 dev eth1 # 添加网卡 IP 地址 ip a del 172.16.1.23/24 dev eth1 # 删除网卡 IP 地址 ip link show dev eth0 # 显示网卡设备属性 ip link set eth1 up # 激活网卡 ip link set eth1 down # 关闭网卡 ip link set eth1 address {mac} # 修改 MAC 地址 ip neighbour # 查看 ARP 缓存 ip route # 查看路由表 ip route add 10.1.0.0/24 via 10.0.0.253 dev eth0 # 添加静态路由 ip route del 10.1.0.0/24 # 删除静态路由 ifconfig # 显示所有网卡和接口信息 ifconfig -a # 显示所有网卡（包括开机没启动的）信息 ifconfig eth0 # 指定设备显示信息 ifconfig eth0 up # 激活网卡 ifconfig eth0 down # 关闭网卡 ifconfig eth0 192.168.120.56 # 给网卡配置 IP 地址 ifconfig eth0 10.0.0.8 netmask 255.255.255.0 up # 配置 IP 并启动 ifconfig eth0 hw ether 00:aa:bb:cc:dd:ee # 修改 MAC 地址 nmap 10.0.0.12 # 扫描主机 1-1000 端口 nmap -p 1024-65535 10.0.0.12 # 扫描给定端口 nmap 10.0.0.0/24 # 给定网段扫描局域网内所有主机 nmap -O -sV 10.0.0.12 # 探测主机服务和操作系统版本 ############################################################################## 有趣的命令 ############################################################################## man hier # 查看文件系统的结构和含义 man test # 查看 posix sh 的条件判断帮助 man ascii # 显示 ascii 表 getconf LONG_BIT # 查看系统是 32 位还是 64 位 bind -P # 列出所有 bash 的快捷键 mount | column -t # 漂亮的列出当前加载的文件系统 curl ip.cn # 取得外网 ip 地址和服务商信息 disown -a &amp;&amp; exit # 关闭所有后台任务并退出 cat /etc/issue # 查看 Linux 发行版信息 lsof -i port:80 # 哪个程序在使用 80 端口？ showkey -a # 取得按键的 ASCII 码 svn diff | view - # 使用 Vim 来显示带色彩的 diff 输出 mv filename.{old,new} # 快速文件改名 time read # 使用 CTRL-D 停止，最简单的计时功能 cp file.txt{,.bak} # 快速备份文件 sudo touch /forcefsck # 强制在下次重启时扫描磁盘 find ~ -mmin 60 -type f # 查找 $HOME 目录中，60 分钟内修改过的文件 curl wttr.in/~beijing # 查看北京的天气预报 echo ${SSH_CLIENT%% *} # 取得你是从什么 IP 链接到当前主机上的 echo $[RANDOM%X+1] # 取得 1 到 X 之间的随机数 bind -x '&quot;\\C-l&quot;:ls -l' # 设置 CTRL+l 为执行 ls -l 命令 find / -type f -size +5M # 查找大于 5M 的文件 chmod --reference f1 f2 # 将 f2 的权限设置成 f1 一模一样的 curl -L cheat.sh # 速查表大全 ############################################################################## 常用技巧 ############################################################################## 列出最常使用的命令 history | awk '{a[$2]++}END{for(i in a){print a[i] &quot; &quot; i}}' | sort -rn | head 列出所有网络状态：ESTABLISHED / TIME_WAIT / FIN_WAIT1 / FIN_WAIT2 netstat -n | awk '/^tcp/ {++tt[$NF]} END {for (a in tt) print a, tt[a]}' 通过 SSH 来 mount 文件系统 sshfs name@server:/path/to/folder /path/to/mount/point 显示前十个运行的进程并按内存使用量排序 ps aux | sort -nk +4 | tail 在右上角显示时钟 while sleep 1;do tput sc;tput cup 0 (((((((tput cols)-29));date;tput rc;done&amp; 从网络上的压缩文件中解出一个文件来，并避免保存中间文件 wget -qO - &quot;http://www.tarball.com/tarball.gz&quot; | tar zxvf - 性能测试：测试处理器性能 python -c &quot;import test.pystone;print(test.pystone.pystones())&quot; 性能测试：测试内存带宽 dd if=/dev/zero of=/dev/null bs=1M count=32768 Linux 下挂载一个 iso 文件 mount /path/to/file.iso /mnt/cdrom -oloop 通过主机 A 直接 ssh 到主机 B ssh -t hostA ssh hostB 下载一个网站的所有图片 wget -r -l1 --no-parent -nH -nd -P/tmp -A&quot;.gif,.jpg&quot; http://example.com/images 快速创建项目目录 mkdir -p work/{project1,project2}/{src,bin,bak} 按日期范围查找文件 find . -type f -newermt &quot;2010-01-01&quot; ! -newermt &quot;2010-06-01&quot; 显示当前正在使用网络的进程 lsof -P -i -n | cut -f 1 -d &quot; &quot;| uniq | tail -n +2 Vim 中保存一个没有权限的文件 :w !sudo tee &gt; /dev/null % 在 .bashrc / .bash_profile 中加载另外一个文件（比如你保存在 github 上的配置） source ~/github/profiles/my_bash_init.sh 反向代理：将外网主机（202.115.8.1）端口（8443）转发到内网主机 192.168.1.2:443 ssh -CqTnN -R 0.0.0.0:8443:192.168.1.2:443 user@202.115.8.1 正向代理：将本地主机的 8443 端口，通过 192.168.1.3 转发到 192.168.1.2:443 ssh -CqTnN -L 0.0.0.0:8443:192.168.1.2:443 user@192.168.1.3 socks5 代理：把本地 1080 端口的 socks5 的代理请求通过远程主机转发出去 ssh -CqTnN -D localhost:1080 user@202.115.8.1 终端下正确设置 ALT 键和 BackSpace 键 http://www.skywind.me/blog/archives/2021 ############################################################################## 有用的函数 ############################################################################## 自动解压：判断文件后缀名并调用相应解压命令 function q-extract() { if [ -f $1 ] ; then case $1 in *.tar.bz2) tar -xvjf $1 ;; *.tar.gz) tar -xvzf $1 ;; *.tar.xz) tar -xvJf $1 ;; *.bz2) bunzip2 $1 ;; *.rar) rar x $1 ;; *.gz) gunzip $1 ;; *.tar) tar -xvf $1 ;; *.tbz2) tar -xvjf $1 ;; *.tgz) tar -xvzf $1 ;; *.zip) unzip $1 ;; *.Z) uncompress $1 ;; *.7z) 7z x $1 ;; *) echo &quot;don't know how to extract '$1'...&quot; ;; esac else echo &quot;'$1' is not a valid file!&quot; fi } 自动压缩：判断后缀名并调用相应压缩程序 function q-compress() { if [ -n &quot;$1&quot; ] ; then FILE=$1 case $FILE in .tar) shift &amp;&amp; tar -cf $FILE $ ;; .tar.bz2) shift &amp;&amp; tar -cjf $FILE $ ;; .tar.xz) shift &amp;&amp; tar -cJf $FILE $ ;; .tar.gz) shift &amp;&amp; tar -czf $FILE $ ;; .tgz) shift &amp;&amp; tar -czf $FILE $ ;; .zip) shift &amp;&amp; zip $FILE $ ;; .rar) shift &amp;&amp; rar $FILE $ ;; esac else echo &quot;usage: q-compress &lt;foo.tar.gz&gt; ./foo ./bar&quot; fi } 漂亮的带语法高亮的 color cat ，需要先 pip install pygments function ccat() { local style=&quot;monokai&quot; if [ # -eq 0 ]; then pygmentize -P style=style -P tabsize=4 -f terminal256 -g else for NAME in @;dopygmentize−Pstyle=@; do pygmentize -P style=@;dopygmentize−Pstyle=style -P tabsize=4 -f terminal256 -g &quot;$NAME&quot; done fi } ############################################################################## 好玩的配置 ############################################################################## 放到你的 ~/.bashrc 配置文件中，给 man 增加漂亮的色彩高亮 export LESS_TERMCAP_mb=&#039;\\E[1m\\E[32m&#039; export LESS_TERMCAP_mh='\\E[2m' export LESS_TERMCAP_mr=&#039;\\E[7m&#039; export LESS_TERMCAP_md='\\E[1m\\E[36m' export LESS_TERMCAP_ZW=&quot;&quot; export LESS_TERMCAP_us=&#039;\\E[4m\\E[1m\\E[37m&#039; export LESS_TERMCAP_me='\\E(B\\E[m' export LESS_TERMCAP_ue=&#039;\\E[24m\\E(B\\E[m&#039; export LESS_TERMCAP_ZO=&quot;&quot; export LESS_TERMCAP_ZN=&quot;&quot; export LESS_TERMCAP_se='\\E[27m\\E(B\\E[m' export LESS_TERMCAP_ZV=&quot;&quot; export LESS_TERMCAP_so=$'\\E[1m\\E[33m\\E[44m' ALT+hjkl/HJKL 快速移动光标，将下面内容添加到 ~/.inputrc 中可作用所有工具， 包括 bash/zsh/python/lua 等使用 readline 的工具，帮助见：info rluserman &quot;\\eh&quot;: backward-char &quot;\\el&quot;: forward-char &quot;\\ej&quot;: next-history &quot;\\ek&quot;: previous-history &quot;\\eH&quot;: backward-word &quot;\\eL&quot;: forward-word &quot;\\eJ&quot;: beginning-of-line &quot;\\eK&quot;: end-of-line ############################################################################## References ############################################################################## https://github.com/Idnan/bash-guide http://www.linuxstall.com/linux-command-line-tips-that-every-linux-user-should-know/ https://ss64.com/bash/syntax-keyboard.html http://wiki.bash-hackers.org/commands/classictest https://www.ibm.com/developerworks/library/l-bash-test/index.html https://www.cyberciti.biz/faq/bash-loop-over-file/ https://linuxconfig.org/bash-scripting-tutorial https://github.com/LeCoupa/awesome-cheatsheets/blob/master/languages/bash.sh https://devhints.io/bash https://github.com/jlevy/the-art-of-command-line https://yq.aliyun.com/articles/68541 vim: set ts=4 sw=4 tw=0 et : ","link":"https://cooker.github.io/post/bash-su-cha-biao/"},{"title":"MySQL 分库、分表","content":" 单KEY 当数据量越来越大时，需要多用户中心进行水平切分，常见的水平切分算法有“范围法”和“哈希法’。 范围法 优点 切分策略简单，根据uid，按照范围，user-center很快能够定位到数据在哪个库 上。 扩容简单，如果容量不够，只要增加user-db3即可： 缺点 uid必须要满足递增的特性。 数据量不均，新增的user-db3，在初期的数据会比较少。 请求量不均，一般来说，新注册的用户活跃度会比较高，故user-db2往往会比user- db1负载要高，导致服务器利用率不平衡。 哈希法 优点 切分策略简单，根据uid，按照hash，user-center很快能够定位到数据在哪个库 上。 数据量均衡，只要uid是均匀的，数据在各个库上的分布一定是均衡的。 请求量均衡，只要uid是均匀的，负载在各个库上的分布一定是均衡的。 缺点 扩容麻烦，如果容量不够，要增加一个库，重新hash可能会导致数据迁移，如何平 滑的进行数据迁移，是一个需要解决的问题 1对多KEY 在数据量较大，并发量较大的时候，通常通过元数据与索引数据分离的架构来满足不同类型的需求 索引表法 思路：建一个只有索引的表 缓存映射法 思路：访问索引表性能较低，把映射表放到缓存里 1. 如果数据量过大，可以通过login_name进行cache水平切分 潜在不足：多一次cache查询 基因法 ++ 潜在问题一：同一个uid发布的tid落在同一个库上，会不会出现数据不均衡？ 回答：只要uid是均衡的，每个用户发布的平均帖子数是均衡的，每个库的数据就是均衡的。 ++ 潜在问题二：最开始分16库，分库基因是4bit，未来要扩充成32库，分库基因变成了5bit，那怎么办？ 回答：需要提前做好容量预估，例如事先规划好5年内数据增长256库足够，就提前预留8bit基因。 多KEY 订单中心是一个非常常见的“多key”业务，主要提供订单的查询与修改的服务，其核心元 数据为： Order(oid, buyer_uid, sellerLuid, time, money, detail.);其中： oid为订单ID，主键 buyer_uid为买家uid seller_uid为卖家uid time, money, detail,….等为订单属性 前台访问，最典型的有三类需求： 订单实体查询：通过oid查询订单实体，90%流量属于这类需求。 用户订单列表查询：通过buyer_uid分页查询用户历史订单列表，9％流量属于这类需求。 商家订单列表查询：通过seller_uid分页查询商家历史订单列表，1%流量属于这类需求。 多对多KEY 对于像订单中心一样复杂的“多key&quot;类业务，在数据量较大，需要对数据库进行水平切分 时，对于后台需求，采用”前台与后台分离”的架构设计方法 数据冗余的方法有很多种： 服务同步双写。 服务异步双写。 线下异步双写（上图所示，是线下异步双写）。 最终一致性，是高吞吐互联网业务一致性的常用实践。保证数据最终一致性的方案有三种： 冗余数据全量定时扫描。 冗余数据增量日志扫描。 冗余数据线上消息实时检测。 shardingJDBC 使用 文档 ","link":"https://cooker.github.io/post/mysql-fen-ku-fen-biao/"},{"title":"MySQL 常用语法","content":" 数据导出 mysqldump -uroot -p [db] [table] -w &quot;id=50[条件]&quot; --no-create-info &gt; [文件名].sql 查询 使用变量 set @cardNo = 'test0012'; -- 变量 SELECT * from mkt_bz_card where card_no = @cardNo; Explain explain select * from emp where name = 'Jefabc'; 批量新增 https://dev.mysql.com/doc/refman/5.7/en/insert.html 1. replace into -- 先删除，再新增 replace into test_tbl (id,name) values (1,'a'),(2,'b'),(3,'y'); 2. insert into on duplicate key update insert into test_tbl (id,name) values (1,'a'),(2,'b'),(x,'y') on duplicate key update name=values(name); 创建临时表，先更新临时表，然后从临时表中update create temporary table tmp(id int(4) primary key, name varchar(50)); insert into tmp values (0,'gone'), (1,'xx'),(m,'yy'); update test_tbl, tmp set test_tbl.dr=tmp.dr where test_tbl.id=tmp.id; when case 条件更新 UPDATE t_user SET age = CASE id WHEN 1 THEN 23 WHEN 2 THEN 24 WHEN 3 THEN 25 END, name = CASE id WHEN 1 THEN '张飞2' WHEN 2 THEN '关羽2' WHEN 3 THEN '刘备2' END WHERE id IN (1,2,3) INSERT ... SELECT Statement INSERT INTO tbl_temp2 (fld_id) SELECT tbl_temp1.fld_order_id FROM tbl_temp1 WHERE tbl_temp1.fld_order_id &gt; 100; 显示进程 show full processlist; ","link":"https://cooker.github.io/post/mysql-chang-yong-yu-fa/"},{"title":"MySQL Docker安装","content":"docker 安装 Linux sudo docker run -p 3306:3306 --name mysql \\ -v /usr/local/docker/mysql/conf:/etc/mysql \\ -v /usr/local/docker/mysql/logs:/var/log/mysql \\ -v /usr/local/docker/mysql/data:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=123456 \\ -d mysql:5.7 Windows docker run -p 3306:3306 --name mysql -v d:/mysql/conf:/etc/mysql -v d:/mysql/logs:/var/log/mysql -v d:/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7 检查容器是否正确运行 docker container ls 进入容器 sudo docker exec -it mysql bash mysql -uroot -p123456 关闭防火墙 # 开放端口： $ systemctl status firewalld $ firewall-cmd --zone=public --add-port=3306/tcp -permanent $ firewall-cmd --reload # 关闭防火墙： $ sudo systemctl stop firewalld 修改访问权限 $ sudo docker exec -it mysql bash $ mysql -uroot -p123456 mysql&gt; grant all privileges on *.* to root@'%' identified by &quot;password&quot;; ","link":"https://cooker.github.io/post/mysql-docker-an-zhuang/"},{"title":"MySQL 主从复制","content":"https://mp.weixin.qq.com/s/rNHwd0QlkZdXMSuVhzjGKA ","link":"https://cooker.github.io/post/mysql-zhu-cong-fu-zhi/"},{"title":"SQL 优化","content":" 在 MySQL 5.0 之前的版本尽量避免使用or查询 表很小，直接全票扫描比走索引快 ON 或 WHERE 条件里面没有用索引 条件里面的索引列使用常量进行比较 一张表一个索引条件的占比很大，可以添加一个基数小的索引条件进行查询 用FORCE INDEX (index_for_column)强制走索引【use index (index_for_column) 只是建议走索引】 --max-seeks-for-key=1000或使用SET max_seeks_for_key=1000告诉优化器假定没有键扫描导致超过1000个键查找。请参见第5.1.7节“服务器系统变量”。 批量insert数据 关闭自动提交。每秒提交数百次会限制性能（受存储设备的写入速度限制） 请关闭自动提交模式，因为它会在每次插入时对磁盘执行日志刷新 SET autocommit=0; ... SQL import statements ... COMMIT; 如果您UNIQUE对辅助键有限制，则可以通过在导入会话期间暂时关闭唯一性检查来加快表的导入 SET unique_checks=0; ... SQL import statements ... SET unique_checks=1; 如果FOREIGN KEY表中有约束，可以通过在导入会话的持续时间内关闭外键检查来加快表的导入： SET foreign_key_checks=0; ... SQL import statements ... SET foreign_key_checks=1; INSERT 如果需要插入许多行， 请使用多行语法来减少客户端和服务器之间的通信开销： INSERT INTO yourtable VALUES (1,2), (5,5), ...; AUTO_INCREMENT 自增ID 处理 innodb_autoinc_lock_mode=0 传统锁定模式 innodb_autoinc_lock_mode=1 连续锁定模式 innodb_autoinc_lock_mode=2 交错锁定模式 自增出现异常，id也会增长 自增id设置 auto_increment_offset+ N× auto_increment_increment SELECT 优化 子查询优化 ((a AND b) AND c OR (((a AND b) AND (c AND d)))) -&gt; (a AND b AND c) OR (a AND b AND c AND d) 删除不必要的括号 (b&gt;=5 AND b=5) OR (b=6 AND 5=5) OR (b=7 AND 5=6) -&gt; b=5 OR b=6 取消恒定的条件 outer_expr IN (SELECT inner_expr FROM ... WHERE subquery_where) 优化方式1： 如果需要要null EXISTS (SELECT 1 FROM ... WHERE subquery_where AND outer_expr=inner_expr) 如果不需要null outer_expr is not null in 和 exists 区别， in 用于内部查询表比外部查询表小的时候，exists 用于内部查询表比外部查询表大的时候 exists 会占用额外的空间，只对外部查询进行是否存在判断、in 会进行嵌套for 循环遍历 索引使用的常量表达式仅计算一次。索引=（计算 1+1），不能 索引+1=值 范围查询 Hash 索引 =， &lt;=&gt;， IN()，IS NULL，或IS NOT NULL BTree 索引 &gt;， &lt;， &gt;=， &lt;=， BETWEEN， !=，或 &lt;&gt; ，like 通配符不能放在最前面 使用use index(索引) 进行强制走索引 强制控制优化器：https://dev.mysql.com/doc/refman/5.6/en/index-hints.html 例子：强制走索引 SELECT * FROM table1 USE INDEX (col1_index,col2_index) WHERE col1=1 AND col2=2 AND col3=3; 例子：忽略索引 SELECT * FROM table1 IGNORE INDEX (col3_index) WHERE col1=1 AND col2=2 AND col3=3; Is null 优化 排序优化 https://dev.mysql.com/doc/refman/5.6/en/order-by-optimization.html 设置 sort_buffer_size 默认256K 对于未使用的慢ORDER BY查询 filesort，请尝试将max_length_for_sort_data 系统变量降低 为适合触发的值 filesort。（将此变量的值设置得太高的症状是磁盘活动过多和CPU活动较低的组合。） ORDER BY执行计划信息可用 使用 EXPLAIN （请参见第8.8.1节“使用EXPLAIN优化查询”），可以检查MySQL是否可以使用索引来解析ORDER BY子句： 如果输出Extra列 EXPLAIN不包含Using filesort，则使用索引，filesort而不执行a。 如果输出Extra列 EXPLAIN包含 Using filesort，则不使用索引并filesort执行a。 分组优化 （有临时表） 尽量避免默认排序 DISTINCT优化 DISTINCT ORDER BY在很多情况下，结合需要一个临时表。 在大多数情况下，DISTINCT子句可以视为的特殊情况GROUP BY。例如，以下两个查询是等效的： SELECT DISTINCT c1, c2, c3 FROM t1 WHERE c1 &gt; const; SELECT c1, c2, c3 FROM t1 WHERE c1 &gt; const GROUP BY c1, c2, c3; limit 优化 Limit 会影响order by执行计划 mysql&gt; SELECT * FROM ratings ORDER BY category; +----+----------+--------+ | id | category | rating | +----+----------+--------+ | 1 | 1 | 4.5 | | 5 | 1 | 3.2 | | 3 | 2 | 3.7 | | 4 | 2 | 3.5 | | 6 | 2 | 3.5 | | 2 | 3 | 5.0 | | 7 | 3 | 2.7 | +----+----------+--------+ mysql&gt; SELECT * FROM ratings ORDER BY category LIMIT 5; +----+----------+--------+ | id | category | rating | +----+----------+--------+ | 1 | 1 | 4.5 | | 5 | 1 | 3.2 | | 4 | 2 | 3.5 | | 3 | 2 | 3.7 | | 6 | 2 | 3.5 | +----+----------+--------+ 如果id是唯一的，可以加上id进行排序 mysql&gt; SELECT * FROM ratings ORDER BY category, id; +----+----------+--------+ | id | category | rating | +----+----------+--------+ | 1 | 1 | 4.5 | | 5 | 1 | 3.2 | | 3 | 2 | 3.7 | | 4 | 2 | 3.5 | | 6 | 2 | 3.5 | | 2 | 3 | 5.0 | | 7 | 3 | 2.7 | +----+----------+--------+ mysql&gt; SELECT * FROM ratings ORDER BY category, id LIMIT 5; +----+----------+--------+ | id | category | rating | +----+----------+--------+ | 1 | 1 | 4.5 | | 5 | 1 | 3.2 | | 3 | 2 | 3.7 | | 4 | 2 | 3.5 | | 6 | 2 | 3.5 | +----+----------+--------+ 范围优化 去除非索引绝对为true 或 false 的条件，如1=1，like '%**' 查询in、or里面的查询条件的数量多并且不是唯一索引的时候会印象性能 存在单索引FORCE INDEX索引提示。这样的想法是，如果强制使用索引，那么执行潜入索引的额外开销将无济于事。 索引不是唯一索引，不是 FULLTEXT索引。 没有子查询。 没有DISTINCT，GROUP BY或ORDER BY子句存在。 索引合并 避免AND、OR混合使用 (x AND y) OR z =&gt; (x OR z) AND (y OR z) (x OR y) AND z =&gt; (x AND z) OR (y AND z) 可以考虑使用union 、union all union 会进行出重操作 外连接优化 如果left join 或 right join 匹配到的行是null，且处理过程中不要这些null行 可以考虑使用inner join（内连接） 好处：left join、right join 会出现查出大表后再查小表的情况，inner join 会自动选择出小表、然后再去查大表 能大大小了table中匹配行 函数调用优化 MySQL函数在内部被标记为确定性或不确定性。不确定函数有RAND()、UUID()等 主键递增，数据行写入可以提高插入性能，可以避免page分裂，减少表碎片提升空间和 内存的使用 主键要选择较短的数据类型， Innodb引擎普通索引都会保存主键的值，较短的数据类 型可以有效的减少索* 引的磁盘空间，提高索引的缓存效率 无主键的表删除，在row模式的主从架构，会导致备库夯住 选择性：select COUNT(DISTINCT LEFT(id_address,3))/COUNT(*) ; 越接近1查询性能越好。 资料 https://mp.weixin.qq.com/s/X9_nQ8iPx3ViaMBhZ3H33A ","link":"https://cooker.github.io/post/sql-you-hua/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://cooker.github.io/post/hello-gridea/"}]}